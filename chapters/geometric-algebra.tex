% \setchapterpreamble[r][.9\textwidth]{
% 	\dictum[Lewis Carroll]{``Begin at the beginning, the King said dictum, ``and go on till you come to the end: then stop.''}
% }


\chapter{The Geometric Algebra}
\label{cha:geometric-algebra}


In \cref{cha:preliminary-theory}, we defined the metric-independent exterior algebra of multivectors over a vector space $V$.
While metrical operations can be achieved by tacking the Hodge dual onto $\EA{V}$, the geometric algebra is a generalisation of $\EA{V}$ which has the metric (and concomitant notions of orientation and duality) directly built-in.

Geometric algebras are also known as real \emph{Clifford algebras} $Cl(V, q)$ after their first inventor \cite{clifford1878grassmann}.
Especially in mathematics, Clifford algebras are defined in terms of a quadratic form $q$, and the vector space $V$ may be complex.
However, in physics, where $V$ is taken to be real and a metric $η$ is usually supplied instead of $q$, the name ``geometric algebra'' is preferred.\sidenote{
	The newer name was coined by David Hestenes in the 1970s, who popularised Clifford algebra for physics \cite{hestenes1986ga-unified-language,hestenes1968ga}.
}

\section{Construction and Overview}

Informally put, the geometric algebra is obtained by enforcing the single rule
\begin{align}
	\label{eqn:square-is-innerprod}
	𝒖^2 = \ip{𝒖, 𝒖}
\end{align}
for any vector $𝒖$, along with the associative algebra axioms of \cref{def:associative-algebra}.
The rich algebraic structure which follows from this is remarkable.
Formally, we may give the geometric algebra as a quotient, just like our presentation of $\EA{V}$.
\begin{definition}
	Let $V$ be a finite-dimensional real vector space with metric.
	The \textdef{geometric algebra} over $V$ is
	\begin{align}
		\GA(V, η) ≔ \quot{\TA{V}}{\gen{𝒖⊗𝒖 - \ip{𝒖, 𝒖}}}
	.\end{align}
\end{definition}
The ideal defines the congruence generated by $𝒖⊗𝒖 \sim \ip{𝒖, 𝒖}$, encoding \cref{eqn:square-is-innerprod}.
This uniquely defines the associative (but not generally commutative) \emph{geometric product} which we denote by juxtaposition.

As $2^n$-dimensional vector spaces, $\GA(V, η)$ and $\EA{V}$ are isomorphic, each with a $\binom{n}{k}$-dimensional subspace for each grade $k$.
Denoting the $k$-grade subspace $\GA[k](V, η)$, we have the vector space decomposition
\begin{align}
	\GA(V, η) = \bigoplus_{k = 0}^∞ \GA[k](V, η)
.\end{align}
Note that this is not a $\ZZ$ grading of the geometric algebra: the quotient is by \emph{inhomogeneous} elements $𝒖 ⊗ 𝒖 - \ip{𝒖, 𝒖} ∈ \TA[2]{V} ⊕ \TA[0]{V}$, and therefore the geometric product of a $p$-vector and a $q$-vector is not generally a $(p + q)$-vector.
However, the congruence \emph{is} homogeneous with respect to the $\ZZ_2$-grading, so $\GA(V, η)$ is $\ZZ_2$-graded.
This shows that the algebra separates into `even' and `odd' subspaces
\begin{fullwidth}
	\begin{align}
		\GA(V, η) = \GA[+](V, η) ⊕ \GA[-](V, η)
		\qqtext{where}
		\begin{cases}
			\GA[+](V, η) = \bigoplus_{k = 0}^∞ \GA[2k](V, η)
		\\	\GA[+](V, η) = \bigoplus_{k = 0}^∞ \GA[2k + 1](V, η)	
		\end{cases}
	\end{align}
\end{fullwidth}
where $\GA[+](V, η)$ is closed under the geometric product, forming the \textdef{even subalgebra}.





\subsubsection{The geometric product of vectors}

% By expanding $(𝒖 + 𝒗)^2 = \ip{𝒖 + 𝒗, 𝒖 + 𝒗}$, it directly follows\sidenote{
% 	$𝒖^2 + 𝒗𝒖 + 𝒖𝒗 + 𝒗^2 = \ip{𝒖,𝒖} + 2\ip{𝒖,𝒗} + \ip{𝒗,𝒗}$
% } that
By expanding $(𝒖 + 𝒗)^2 = \ip{𝒖 + 𝒗, 𝒖 + 𝒗}$, it directly follows that
\begin{align}
	\ip{𝒖, 𝒗} = \frac12(𝒖𝒗 + 𝒗𝒖)
.\end{align}
We recognise this as the symmetrised product of two vectors.
The remaining antisymmetric part coincides with the \emph{alternating} or \emph{wedge} product familiar from exterior algebra
\begin{align}
	𝒖 ∧ 𝒗 = \frac12(𝒖𝒗 - 𝒗𝒖)
.\end{align}
This is a $2$-vector, or bivector, in $\GA[2](V, η)$.
Thus, the geometric product on vectors is
\begin{align}
	\label{eqn:geometric-prod-of-vectors}
	𝒖𝒗 = \ip{𝒖, 𝒗} + 𝒖∧𝒗
,\end{align}
and some important features are immediate:
\begin{itemize}
	\item \emph{Parallel vectors commute, and vice versa:}
	If $𝒖 = λ𝒗$, then $𝒖∧𝒗 = 0$ and $𝒖𝒗 = \ip{𝒖,𝒗} = \ip{𝒗,𝒖} = 𝒗𝒖$.
	\item \emph{Orthogonal vectors anti-commute, and vice versa:}
	If $\ip{𝒖,𝒗} = 0$, then $𝒖𝒗 = 𝒖∧𝒗 = -𝒗∧𝒖 = -𝒗𝒖$.
\end{itemize}
In particular, if $\set{\ve_i} ⊂ V$ is an orthonormal basis, then we have $\ve_i^2 = \ip{\ve_i, \ve_i}$ and $\ve_i\ve_j = -\ve_j\ve_i$, which can be summarised by the anticommutation relation
\begin{math}
	% \frac12\qty{\ve_i, \ve_j} = η_{ij}
	\ve_i\ve_j + \ve_j\ve_i = 2η_{ij}
.\end{math}
\begin{itemize}
	\item \emph{Vectors are invertible under the geometric product:}
	If $𝒖$ is a vector for which the scalar $𝒖^2$ is non-zero, then $𝒖^{-1} = 𝒖/𝒖^2$.

	\item \emph{Geometric multiplication produces objects of mixed grade:}
	The product $𝒖𝒗$ has a scalar part $\ip{𝒖,𝒗}$ and a bivector part $𝒖∧𝒗$.
\end{itemize}

\subsubsection{Higher-grade elements}
\label{sec:higher-grade-elements}


As with two vectors, the geometric product of two homogeneous multivectors is generally inhomogeneous.
We can gain insight by separating geometric products into grades and studying each part.
\begin{definition}
	The linear \textdef{grade projection} operator is defined on blades by
	\begin{align}
		\grade[k]{A} =
		\begin{cases}
			A & \text{if $A = \etc{𝒖_\i}∧k$}
		\\	0 & \text{otherwise}
		\end{cases}
	.\end{align}
\end{definition}
We can generalise the definition of the wedge product of vectors $𝒖∧𝒗 = \grade[2]{𝒖𝒗}$ to arbitrary homogeneous multivectors by taking the highest-grade part of their product,
\begin{align}
	A ∧ B = \grade[p + q]{AB}
,\end{align}
where $A ∈ \GA[p](V, η)$ and $B ∈ \GA[q](V, η)$.
Dually, we can define an inner product on homogeneous multivectors by taking the lowest-grade part, $|p - q|$.
These can be extended by linearity to inhomogeneous elements.
\begin{definition}
	\label{def:wedge-and-fat-dot-for-multivectors}
	Let $A, B ∈ \GA(V, η)$ be possibly inhomogeneous multivectors.
	The \textdef{wedge product is}
	\begin{align}
		A∧B ≔ \sum_{p,q}\grade[p + q]{\grade[p]{A}\grade[q]{B}}
	,\end{align}
	and the \textdef{generalised inner product}, or ``fat'' dot product,\sidenote{
		Various `inner products' have been proposed for geometric algebra, but the definition here is arguably the simplest and best behaved; see \cite{dorst2002inner-products} for closer discussion.
	} is
	\begin{align}
		A \fatdot B ≔ \sum_{p,q}\grade[|p - q|]{\grade[p]{A}\grade[q]{B}}
	.\end{align}
\end{definition}

With the wedge product defined on all of $\GA(V, η)$, we use language of multivectors as we did with the exterior algebra, so that $\etc{𝒖_\i}∧k ∈ \GA[k](V, η)$ is a $k$-blade, and a sum of $k$-blades is a $k$-multivector, etcetea.

The products in \cref{def:wedge-and-fat-dot-for-multivectors} work together nicely; the induced metric on $k$-vectors introduced in \cref{sec:metrical-exterior-alg} is expressible in any of the following ways.
\begin{align}
	\label{eqn:induced-metric-ga}
	\ip{A, B} = \revsign{k} \, \grade{AB}
	= \grade{\rev{A}B} = \grade{A\rev{B}}
	= \rev{A} \fatdot B = A \fatdot \rev{B}
,\end{align}
The reversion in necessary because the vectors in the product of two blades $(\etc{\ve_{i_\i}}{}k)(\etc{\ve_{j_\i}}{}k)$ are paired `inside first'.

% \begin{lemma}
% 	For $k$-vectors $A$ and $B$,
% 	where $\ip{A, B}$ is the induced metric defined in \cref{sec:metrical-exterior-alg}.
% \end{lemma}
% \begin{proof}
% 	All equalities after the first are simple variations of notation.
% 	For the first equality, it suffices to show the case where $A = \etc{\ve_{i_\i}}{}k$ and $B = \etc{\ve_{j_\i}}{}k$ are basis blades with respect to some orthogonal basis $\set{\ve_i}$.

% 	\begin{align}
% 		\grade{A \rev{B}}
% 		= \grade{\etc{\ve^{i_\i}}{}k \etc[k]{\ve_{j_\i}}{}1}
% 	\end{align}

% 	If $i$ or $j$ contain repeated indices, then the left-hand side vanishes by antisymmetry of the wedge product, and the right-hand side by definition.
% 	If $i$ contains no repeated indices, and the $j$ indices are some permutation $j_p = σ(i_p)$, then $\etc{\ve^{i_\i}}∧k = \etc{\ve^{i_\i}}{}k$ by orthogonality.
% 	Rewriting the left-hand side,
% 	\begin{align}
% 		\grade{\etc{\ve^{i_\i}}{}k \etc[k]{\ve_{j_\i}}{}1}
% 		= (-1)^σ \angbr[\big]{
% 			\ve^{i_1}\cdots\underbrace{\ve^{i_k}\ve_{i_k}}_1\cdots\ve_{i_1}
% 		}
% 		= (-1)^σ
% 	.\end{align}
% 	Finally, if $i$ contains no repeated indices, but $j$ is not a permutation of $i$, then there is at least one pair of indices in the symmetric difference of $\set[\big]{i_p}$ and $\set[\big]{j_p}$, say $i_r$ and $j_s$.
% 	Commuting this pair $\ve^{i_r}$ and $\ve_{j_s}$ together shows that the left-hand side vanishes, since $\ve^{i_r}\ve_{j_s} = 0$.
% \end{proof}







\section{Relations to Other Algebras}

An efficient way to become familiar with the geometric algebra is to exemplify its relationships with other algebras and with itself.

\subsection{Fundamental algebra automorphisms}

Operations such complex conjugation $\overline{AB} = \overline{A}\,\overline{B}$ or matrix transposition $(AB)\transpose = B\transpose A\transpose$ are useful because they preserve or reverse multiplication.
Linear functions with this property are called algebra automorphisms or antiautomorphisms, respectively.
The geometric algebra possesses several important \paren{anti}automorphism operations.

Isometries of $(V, η)$ are linear functions $f : V → V$ which preserve the metric, so that $\ip{f(𝒖), f(𝒗)} = \ip{𝒖, 𝒗}$ for any $𝒖, 𝒗 ∈ V$.
Vector spaces always possess the involution isometry $𝒖 ↦ -𝒖$, as well as the trivial isometry.
An isometry extends uniquely to an algebra \paren{anti}automorphism by defining $f(AB) = f(A)f(B)$ or $f(AB) = f(B)f(A)$.
Thus, by extending the two fundamental isometries of $(V, η)$ in the two possible ways, we obtain four fundamental \paren{anti}automorphisms of $\GA(V, η)$.

\begin{definition}
	Let $𝒖 ∈ \GA[1](V, η)$ be a vector and $A, B ∈ \GA(V, η)$ possubly inhomogeneous multivectors in a geometric algebra.
	\begin{itemize}
		\item \textdef{Reversion $\dagger$} is the identity map on vectors $\rev{𝒖} = 𝒖$ extended to general multivectors by the rule $\rev{(AB)} = \rev{B}\rev{A}$.
		
		\item \textdef{Grade involution $\star$} is the extension of the involution $\invol{𝒖} = -𝒖$ to general multivectors by the rule $\invol{(AB)} = \invol{A}\invol{B}$.
	\end{itemize}
\end{definition}
Note that if $A ∈ \GA[k](V, η)$ is a $k$-vector, then $\invol{A} = (-1)^k A$ and $\rev{A} = \revsign{k}A$ where the \textdef{reversion sign}
\begin{margintable}
	\centering
	\begin{tabular}{C|C}
		k \mod 4 & \revsign{k}
	\\	0 & +
	\\	1 & +
	\\	2 & -
	\\	3 & -
	\end{tabular}
\end{margintable}
\begin{align}
	\label{eqn:reversion-sign}
	\revsign{k} ≔ (-1)^{\frac{(k - 1)k}2}
\end{align}
is the sign of the reverse permutation on $k$ symbols.

Reversion and grade involution together generate the four fundamental automorphisms
\begin{center}
	\renewcommand{\arraystretch}{1.2}
	\begin{tabular}{c|cl}
	$\op{id}$ & $\star$ & automorphisms \\
	\cline{1-2}
	$\dagger$ & $\star\circ\dagger$ & anti-automorphisms
	\end{tabular}
\end{center}
\marginnote{
	$\star\circ\dagger$ is sometimes referred to as the \textdef{Clifford conjugate}
}[-2\baselineskip]
which form a group isomorphic to $\ZZ_2^2$ under composition.



These operations are very useful in practice.
In particular, the following result follows easily from reasoning about grades.
\begin{lemma}
	\label{lem:grades-of-square}
	If $A ∈ \GA[k](V, η)$ is a $k$-vector, then $A^2$ is a $4\NN$-multivector, i.e., a sum of blades of grade $\qty{0, 4, 8, \dots}$ only.
\end{lemma}
\begin{proof}
	The multivector $A^2$ is its own reverse, since $\rev{(A^2)} = (\rev{A})^2 = (±A)^2 = A^2$, and hence has parts of grade $\set{4n, 4n + 1 | n ∈ \NN}$.
	Similarly, $A^2$ is self-involutive, since $\invol{(A^2)} = (\invol A)^2 = (±A)^2 = A^2$.
	It is thus of even grade, leaving the possible grades $\set{0, 4, 8, ...}$.
\end{proof}



\subsection{Even subalgebra isomorphisms}

As noted above, multivectors of even grade are closed under the geometric product, and form the even subalgebra $\GA[+](p, q)$.
There is an isomorphism $\GA[+](p, q) \cong \GA[+](q, p)$ given by $\bar{\ve_i} ≔ \ve_i$ with opposite signature $\bar{\ve_i}^2 ≔ -\ve_i^2$, since the factor of $-1$ occurs only an even number of times for even elements.

The even subalgebras are also isomorphic to full geometric algebras of one dimension less:
\begin{lemma}
	\label{lem:even-subalg-isos}
	There are isomorphisms
	\begin{align}
		\GA[+](p,q) ≅ \GA(p,q - 1)
		\qqtext{and}
		\GA[+](p,q)≅ \GA(q,p - 1)
	\end{align}
	when $q ≥ 1$ and $p ≥ 1$, respectively.
\end{lemma}
\begin{proof}
	Select a unit vector $𝒖 ∈ \GA(p, q)$ with $𝒖^2 = -1$, and define a linear map $Ψ_𝒖 : \GA(p, q - 1) → \GA[+](p, q)$ by
	\begin{align}
		Ψ_𝒖(A) =
		\begin{cases}
			A & \text{if $A$ is even}
		\\	A ∧ 𝒖 & \text{if $A$ is odd}
		\end{cases}
	.\end{align}
	Note we are taking $\GA(p, q - 1) ⊂ \GA(p, q)$ to be the subalgebra obtained by removing $𝒖$ (i.e., restricting $V$ to $𝒖^\perp$) so there is a canonical inclusion from the domain of $Ψ_𝒖$ to the codomain.
	Let $A ∈ \GA(p, q - 1)$ be a $k$-vector.
	Note that $A∧𝒖 = A𝒖$ since $𝒖 \perp \GA(p, q - 1)$, and that $A$ commutes with $𝒖$ if $k$ is even and anticommutes if $k$ is odd.

	To show $Ψ_𝒖$ is a homomorphism, suppose $A, B ∈ \GA(p, q - 1)$ are both even;
	then $Ψ_𝒖(AB) = AB = Ψ_𝒖(A)Ψ_𝒖(B)$.
	If both are odd, then $AB$ is even and $Ψ_𝒖(AB) = AB = -AB𝒖^2 = A𝒖B𝒖 = Ψ_𝒖(A)Ψ_𝒖(B)$.
	If $A$ is odd and $B$ even, then $Ψ_𝒖(AB) = AB𝒖 = A𝒖B = Ψ_𝒖(A)Ψ_𝒖(B)$ and similarly for $A$ even and $B$ odd.
	Injectivity and surjectivity are clear, so $Ψ_𝒖$ is an algebra isomorphism.
\end{proof}

The special case $\GA[+](1,3) ≅ \GA(3)$ is of great relevance to special relativity, and is discussed in detail in \cref{sec:spacetime-split}.
Here the isomorphism $Ψ_𝒖$ is called a \emph{space\slash time split} with respect to an observer of velocity $𝒖$.
This provides an impressively efficient algebraic method for transforming relativistic quantities between inertial frames.








\subsection{Relation to exterior forms}

The geometric algebra differs from the algebra of exterior forms in two orthogonal ways:
Firstly, $\GA(V, η)$ is an associative algebra \emph{over} $V$, while $\forms(V)$ is an algebra of alternating maps which act \emph{on} tensor powers of $V$.
Secondly, the product in $\GA(V, η)$ is an intrinsically metrical generalisation of the product in $\EA{V}$.
We will address these two aspects separately, to more clearly see how each is translated between the two algebras.

% The geometric algebra is a generalisation of the exterior algeba.
% Indeed, in the special case of a completely degenerate metric (i.e., $\ip{𝒖, 𝒗}_0 = 0$ for all vectors), then the algebras are identical, $\GA(V, 0) \cong \EA{V}$.
% But even with a nontrivial metric, $\EA{V}$ is embedded in $\GA(V, η)$ by identifying the wedge product of $\EA{V}$ to the wedge product (not the geometric product) of $\GA(V, η)$.


\subsubsection{Exterior forms as multivectors}

Exterior forms can be mimicked in the geometric algebra by making use of a reciprocal basis, as in the following lemma.
\begin{lemma}
	If $A ∈ \GA[k](V, η)$ is a $k$-vector and $φ ∈ \forms[k](V)$ is a $k$-form whose components coincide (i.e., $A_{\etc{i_\i}{}k} = φ_{\etc{i_\i}{}k}$ given a common basis of $V$) then
	\begin{align}
		\ip{A, \etc{𝒖_\i}∧k}
		= k! \, φ(\etc{𝒖_\i}⊗k)
	,\end{align}
	where $\ip{A, B} = A \fatdot \rev{B}$ is the induced metric on $k$-vectors as in \cref{eqn:induced-metric-ga}.
\end{lemma}
The factor of $k!$ is due to the Spivak convention for exterior forms (replace $k! \mapsto 1$ for the Kobayashi--Nomizu convention).
Note that there is no space for a choice of normalisation convention within the geometric algebra.
\begin{proof}
	Unpacking the left-hand side with \cref{eqn:induced-metric}, we have
	\begin{align}
		\ip{A, \etc{𝒖_\i}∧k} = \sum_{σ ∈ S_k} (-1)^σ A_{\etc{i_\i}{}k} \etc{u_{σ(\i)}^{i_\i}}{}k
	,\end{align}
	which since $A_{\etc{i_\i}{}k} = φ_{\etc{i_\i}{}k}$ is equal to
	\begin{align}
		\sum_{σ ∈ S_k} (-1)^σ φ(\etc{𝒖_{σ(\i)}}⊗k) = k! \, φ(\etc{𝒖_\i}⊗k)
	\end{align}
	where all $k!$ terms are equal due to the alternating property of $φ$.
\end{proof}


\subsubsection{Pseudoscalars and Hodge duality}
\label{sec:ga-hodge-dual}

Since the metric is built into the geometric algebra, so are the features of metrical exterior algebra from \cref{sec:metrical-exterior-alg}, including the Hodge dual.
In geometric algebra, Hodge duality is identical to reversion composed with multiplication by the volume element, $\star A = \rev{A}\vol$.

Consider two $k$-vectors $A$ and $B$.
The object $\rev{B}\vol$ is thus a $(n - k)$-vector, and its wedge product with $A$ a pseudoscalar.
From associativity of the geometric product, we immediately have
\begin{align}
	A ∧ (\rev{B}\vol) = \grade[n]{A(\rev{B}\vol)} = \grade[n]{(A\rev{B})\vol} = \grade{A\rev{B}}\vol = \ip{A, B}\vol
,\end{align}
which is the definition of the Hodge dual, \cref{eqn:hodge-dual}.
The reversion is only necessary for exact agreement with $\star$; simple multiplication by the volume element is an appropriate dual operation, differing from $\star$ only by an overall grade-dependent sign.

The $\vol$-duality has the advantage of being trivial to manipulate algebraically,
while also enjoying a simple scalar square
\begin{align}
	\vol^2 = (-1)^s \revsign{n} = (-1)^s (-1)^{n(n-1)/2}
	\marginnote{
		Here $s$ is the signature of the metric, so that $(-1)^s = \det η$.
		% Recall that $(-1)^{n(n-1)/2} = \revsign{n}$ is the reversion sign for grade $n$.
	}
,\end{align}
unlike the Hodge dual, whose square
\begin{align}
	\star^2 A = (-1)^s (-1)^{k(n-k)} A
\end{align}
depends on the grade $k$ on which it acts.\sidenote{
	This follows from \cref{lem:inv-hodge}.
}

\subsubsection{Imitating the geometric product in the exterior algebra}

Using the Hodge dual, the geometric product (of vectors) may be defined entirely within the exterior algebra as
\begin{align}
	\label{eqn:geoprod-in-ea}
	𝒖𝒗 ≔ \star^{-1} (𝒖 ∧ \star 𝒗) + 𝒖 ∧ 𝒗
\end{align}
where $s$ is the signature of the metric.
Indeed, \cref{eqn:geoprod-in-ea} reduces to the familiar formula
\begin{align}
	𝒖𝒗 = \ip{𝒖, 𝒗} \star^{-1} \vol + 𝒖 ∧ 𝒗 = \ip{𝒖, 𝒗} + 𝒖 ∧ 𝒗
\end{align}
by \cref{eqn:hodge-dual}.
However, \cref{eqn:geoprod-in-ea} does not apply to general multivectors, and the equivalent formulae for higher-grade objects are more complex and tend to obscure the underlying simplicity of the geometric product.

The inner product $A \lcontr B$
\begin{lemma}
	Right contraction is expressible in terms of Hodge duality as
	\begin{align}
		B \rcontr \rev{A} = \star^{-1} (A ∧ \star B)
	.\end{align}
\end{lemma}
\begin{proof}
	Begin by reversing the left-hand side and inserting $1 = \vol\vol^{-1}$,
	\begin{align}
		\label{eqn:intprod-duals.1}
		B \rcontr \rev{A}
		= \rev{\qty((A \lcontr \rev{B}) \vol \vol^{-1})}
	.\end{align}
	If $A$ and $B$ are of grades $a$ and $b$, respectively, we can dualise the contraction into a wedge product with
	\begin{align}
		(A \lcontr \rev{B})\vol
		= \grade[b - a]{A\rev{B}}\vol
		&= \grade[n - (b - a)]{A\rev{B}\vol}
		= \grade[a + (n - b)]{A(\rev{B}\vol)}
		= A ∧ (\rev{B}\vol)
	.\end{align}
	Therefore, \cref{eqn:intprod-duals.1} is equal to
	\begin{align}
		\rev{\qty((A ∧ (\rev{B} \vol)) \vol^{-1})}
		= \star^{-1} (A ∧ \star B)
	\end{align}
	using $\star A = \rev{A}\vol$ and $\star^{-1} A = \rev{(A\vol^{-1})}$.
\end{proof}



\subsection{Common algebra isomorphisms}
\label{sec:common-alg-isos}

While $\GA(V, η)$ contains $\EA{V}$ as a subset, one significance difference between the two algebras is the role of inhomogeneous elements.
While inhomogeneous multivectors find little use in exterior algebra,\sidenote{
	In fact, some authors \cite{flanders1963differential} leave sums of terms of $\EA{V}$ of differing grade undefined.
} they have the important role of describing reflections and rotations in $\GA(V, η)$.
Many familiar algebraic structures relating to rotations in relativistic or quantum physics are in fact special cases of geometric algebra.

\begin{itemize}
	\item\textbf{Complex numbers: $\GA[+](2) \cong \CC$}
	
	The complex plane $\CC ≅ \op{span}_\RR\set{1, \ve_1\ve_2}$ is embedded in $\GA(2)$ as the even subalgebra, with the isomorphism
	\begin{align}
	% 	\CC &≅ \GA[+](2)
	% \\	x + iy &↔︎ x + y\ve_1\ve_2
		\CC ∋ x + iy ↔︎ x + y\ve_1\ve_2 ∈ \GA[+](2)
	\end{align}
	Complex conjugation in $\CC$ coincides with reversion in $\GA(2)$.


	\item\textbf{Quaternions: $\GA[+](3) \cong \HH$}

	Similarly, the quaternions are the even subalgebra $\GA[+](3)$, related by the isomorphism\sidenote{
		Note the minus sign.
		Viewed as rotations through their respective normal planes, $(\ii, \jj, \kk)$ form a \emph{left}\hyp handed basis.
		This is because Hamilton chose $\ii\jj\kk = -1$, not $+1$.
	}
	\begin{align}
		% \HH ∋ t + x\ii + y\jj + z\kk ↔︎ t + x\ve_2\ve_3 - y\ve_3\ve_1 + z\ve_1\ve_3 ∈ \GA[+](3)
		q_0 + q_1\ii + q_2\jj + q_3\kk ⟷ q_0 + q_1\ve_2\ve_3 - q_2\ve_3\ve_1 + q_3\ve_1\ve_2
	.\end{align}
	Again, quaternion conjugation corresponds to reversion in $\GA(3)$.



	\item\textbf{Complexified quaternions: $\GA[+](1,3) ≅ \CC ⊗ \HH$}

	The complexified quaternion algebra, which has been applied to special relativity \cite{berry2021quat-sr,deleo1996quat-sr,berry2020quat-sr}, is isomorphic to the subalgebra $\GA[+](1,3)$.
	The isomorphism
	\begin{align}
		\CC⊗\HH &\ni (x + yi) ⊗ (q_0 + q_1\ii + q_2\jj + q_3\kk)
		⟷
	\\	&(x + y \ve_{0123})(q_0 + q_1\ve_{23} - q_2\ve_{31} + q_3\ve_{12})
		\in \GA[+](1, 3)
	\end{align}
	associates quaternion units with bivectors, and the complex plane with the scalar--pseudoscalar plane.
	Reversion in $\GA(1, 3)$ corresponds to quaternion conjugation (preserving the complex $i$).

	\item\textbf{The Pauli algebra: $\GA(3) ≅ \set{σ_i}_{i=1}^3$}

	The \emph{algebra of physical space}, $\GA(3)$, admits a complex representation $\ve_i ⟷ σ_i$ via the Pauli spin matrices
	\begin{align}
		σ_1 &= \mqty(
			 0 & +1 \\
			+1 &  0 \\
		)
	,&	σ_2 &= \mqty(
			 0 & -i \\
			+i &  0 \\
		)
	,&	σ_3 &= \mqty(
			+1 &  0 \\
			 0 & -1 \\
		)
	.\end{align}
	Reversion in $\GA(3)$ corresponds to the adjoint (Hermitian conjugate), and the volume element $\vol ≔ \ve_{123} ⟷ σ_1σ_2σ_3 = i$ corresponds to the unit imaginary.
	

	\item\textbf{The Dirac algebra: $\GA(1,3) ≅ \set{γ_μ}_{μ=0}^3$}

	The relativistic analogue to the Pauli algebra is the Dirac algebra,
	generated by the $4×4$ complex Dirac matrices
	\begin{fullwidth}
		\begin{align}
			γ_0 &= \mqty(
				+1 & 0 \\
				 0 & -1 \\
			)
		,&	γ_1 &= \mqty(
				0 & +σ_1 \\
				-σ_1 & 0 \\
			)
		,&	γ_2 &= \mqty(
				0 & -iσ_2 \\
				+iσ_2 & 0 \\
			)
		,&	γ_3 &= \mqty(
				0 & +σ_3 \\
				-σ_3 & 0 \\
			)
		.\end{align}
	\end{fullwidth}
	These form a complex representation of the \emph{algebra of spacetime}, $\GA(1,3)$, via $\ve_μ ⟷ γ_μ$.
	Again, reversion corresponds to the adjoint, and $\vol ≔ \ve_0\ve_1\ve_2\ve_3 ⟷ γ_0γ_1γ_2γ_3 = -iγ_5$.

\end{itemize}





\section{Rotors and the Associated Lie Groups}
\label{sec:rotors}



There is a consistent pattern to the algebra isomorphisms listed in \cref{sec:common-alg-isos}.
Note how the complex numbers $\CC$ are fit for describing $\SO(2)$ rotations in the plane, and the quaternions $\HH$ describe $\SO(3)$ rotations in $\RR^3$.
Common to both their respective isomorphisms with $\GA[+](2)$ and $\GA[+](3)$ is the identification of each ``imaginary unit'' in $\CC$ or $\HH$ with a \emph{unit bivector} in $\GA(n)$.
\begin{itemize}
	\item In $2$d, there is one linearly independent bivector, $\ve_1\ve_2$, and one imaginary unit, $i$.
	\item In $3$d, there are $\dim \GA[2](3) = \binom{3}{2} = 3$ such bivectors, and so three imaginary units $\set{\ii, \jj, \kk}$ are needed.
	\item In $(1+3)$d, we have $\dim \GA[2](1,3) = \binom{4}{2} = 6$, corresponding to three `spacelike' $\set{\ii, \jj, \kk}$ and three `timelike' $\set{i\ii, i\jj, i\kk}$ units of $\CC ⊗ \HH$.
\end{itemize}
The interpretation of a bivector is clear: it takes the role of an `imaginary unit', generating a rotation through the oriented plane which it spans.



To see how bivectors act as rotations, observe that rotations in the $\CC$-plane may be described as mappings
\begin{math}
	z ↦ e^{θi}z
,\end{math}
while $\RR^3$ rotations are described in $\HH$ using a double-sided transformation law,
\begin{math}
	% u → e^{\fracθ2\hat n}ue^{-\fracθ2\hat n}
	u ↦ e^{θ\vb{\hat n}/2}ue^{-θ\vb{\hat n}/2}
,\end{math}
where $\vb{\hat n} ∈ \spanof{\ii, \jj, \kk}$ is a unit quaternion defining the plane of rotation.
Due to the commutativity of $\CC$, the double-sided transformation law is actually general to both $\CC$ and $\HH$.
The same is true for rotations in a geometric algebra, where a multivector is rotated by
\begin{align}
	\label{eqn:rotor-application}
	% u &↦ \rev{R}uR
	A &↦ e^{θ\hat{b}/2} A e^{-θ\hat{b}/2}
,\end{align}
where $\hat{b} ∈ \GA[2](V, η)$ is a unit bivector.
Multivectors of the form $R = e^σ$ for $σ ∈ \GA[2](V, η)$ are called \emph{rotors}.
Immediate advantages to the rotor formalism are clear:
\begin{itemize}
	\item \emph{It is general to $n$ dimensions, and to any metric signature.}

	Rotors describe generalised rotations,\sidenote{a.k.a., proper orthogonal transformations} depending on the metric and algebraic properties of the exponentiated unit bivector $σ$.
	If $σ^2 < 0$, then $e^σ$ describes a Euclidean rotation; if $σ^2 > 0$, then $e^σ$ is a hyperbolic rotation or \emph{Lorentz boost}.

	\item \emph{Vectors are distinguished from bivectors.}

	One of the subtler points about quaternions is their transformation properties under reflection.
	A quaternion `vector' $v = x\ii + y\jj + z\kk$ reflects through the origin as $v \mapsto -v$, but a quaternion `rotor' of the same value is invariant --- vectors and pseudovectors are confused with the same kind of object.
	Not so in the geometric algebra: vectors are $1$-vectors, and $\RR^3$ pseudovectors are bivectors.

	The price of introducing more algebraic objects is hardly a cost but a benefit: the generalisation to arbitrary dimensions is immediate and elegant, and the geometric role of objects becomes clear.\sidenote{
		See \cite{lasenby2016ga-unified-language,hestenes1986ga-unified-language,chappell2016quat-history} for similarly impassioned testaments to the elegance of geometric algebra.
	}
\end{itemize}



\subsection{The rotor groups}

\marginnote{
	\emph{Rotors, spin groups:} \cite[§4.2]{doran2003ga} \cite{hestenes1986ga-unified-language,lie-groups-as-spin-groups}
}[-4.1ex]

We will now see more rigorously how the rotor formalism arises.
An orthogonal transformation in $n$ dimensions may be achieved by the composition of at most $n$ reflections.\sidenote{This is the Cartan--Dieudonné theorem \cite{cartan-dieudonne-theorem}.}
A reflection may be described in the geometric algebra by conjugation with an invertible vector.
For instance, the linear map
\begin{align}
	A \mapsto -𝒗A𝒗^{-1}
	\label{eqn:multivector-reflection}
\end{align}
reflects the multivector $A$ along the vector $𝒗$ --- that is, across the hyperplane with normal $𝒗$.
By composing reflections of this form, any orthogonal transformation may be built, acting on multivectors as
\begin{align}
	\label{eqn:multivector-conjugation-by-inverse}
	A \mapsto \pm RAR^{-1}
\end{align}
for some $R = 𝒗_1𝒗_2\cdots 𝒗_3$, where the sign is positive for an even number of reflections, and negative for odd.

Scaling the axis of reflection $𝒗$ by a non-zero scalar $λ$ does not affect the reflection map \eqref{eqn:multivector-reflection}, since $𝒗 ↦ λ𝒗$ is cancelled out by $𝒗^{-1} ↦ λ^{-1}𝒗^{-1}$.
Therefore, a more direct correspondence exists between reflections and normalised vectors $\hat{𝒗}^2 = ±1$ (although there still remains an overall ambiguity in sign).
For an orthogonal transformation built using normalised vectors,
\begin{align}
	R^{-1} = \hat{𝒗}_3^{-1}\cdots \hat{𝒗}_2^{-1}\hat{𝒗}_1^{-1} = ±\rev{R}	
\end{align}
since $\hat{𝒗}^{-1} = ±\hat{𝒗}$, and hence \cref{eqn:multivector-conjugation-by-inverse} may be written in terms of reversion instead of inversion:
\begin{align}
	\label{eqn:multivector-conjugation}
	A ↦ \pm RA\rev{R}
\end{align}


All such elements $R^{-1} = ±R^†$ taken together form a group under the geometric product.
This is called the \emph{pin} group:
\begin{align}
	\op{Pin}(p, q) ≔ \qty{R \in \GA(p, q) \mid RR^† = ±1}
\end{align}
There are two ``pinors'' for each orthogonal transformation, since $+R$ and $-R$ give the same map \eqref{eqn:multivector-conjugation}.
Thus, the pin group forms a double cover of the orthogonal group $\operatorname{O}(p,q)$.

Furthermore, the even-grade elements of $\op{Pin}(p,q)$ form a subgroup, called the \emph{spin} group:
\begin{align}
	\op{Spin}(p, q) ≔ \qty{R \in \GA[+](p, q) \mid RR^† = ±1}
\end{align}
This forms a double cover of $\SO(p, q)$.

Finally, the additional requirement that $RR^† = 1$ defines the restricted spinor group, or the \emph{rotor} group:
\begin{align}
	\op{Spin}^+(p, q) ≔ \qty{R \in \GA[+](p, q) \mid RR^† = 1}
\end{align}
The rotor group is a double cover of the restricted special orthogonal group $\SO^+(p, q)$.
Except for the degenerate case of $\op{Spin}^+(1, 1)$, the rotor group is simply connected to the identity.

\begin{marginfigure}
\begin{tikzcd}[column sep=tiny, row sep=small]
	\op{Spin}^+ & \op{Spin} & \op{Pin} \\
	\SO^+ & \SO & \operatorname{O}
	\arrow["⊆"{description}, draw=none, from=1-1, to=1-2]
	\arrow["⊂"{description}, draw=none, from=1-2, to=1-3]
	\arrow["⊆"{description}, draw=none, from=2-1, to=2-2]
	\arrow["⊂"{description}, draw=none, from=2-2, to=2-3]
	\arrow[two heads, thin, from=1-1, to=2-1]
	\arrow[two heads, thin, from=1-2, to=2-2]
	\arrow[two heads, thin, from=1-3, to=2-3]
\end{tikzcd}
\caption{Relationships between Lie groups associated with a geometric algebra. An arrow $A \surject B$ signifies that $A$ is a double-cover of $B$.}
\end{marginfigure}


\subsection{The bivector subalgebra}

The multivector commutator product
\begin{align}
	\label{eqn:commutator-prod}
	A × B ≔ \frac12(AB - BA)
\end{align}
enjoys several useful properties, particularly when acting on bivectors.
\begin{lemma}
	\label{lem:commutator-derivation}
	Commutation by a multivector $A$ is a derivation,
	\begin{align}
		A × (BC) = (A × B)C + B(A × C)
	.\end{align}
\end{lemma}
\begin{proof}
	By expanding both sides,
	\begin{align}
		\frac12(ABC - BCA) = \frac12(ABC - CAB + BAC - ACB)
	.\end{align}
\end{proof}
\begin{lemma}
	\label{lem:bivector-comm-grade-preserving}
	Commutation by a bivector $σ$ is a grade-preserving operation; i.e.,
	\begin{math}
		σ × \grade[k]{A} = \grade[k]{σ × A}
	.\end{math}
\end{lemma}
\begin{proof}
	If $A = \grade[k]{A}$ then $Aσ$ and $σA$ are $\set{k - 2, k, k + 2}$-multivectors.
	The $k ± 2$ parts are
	\begin{align}
		\grade[k ± 2]{Α×σ} = \frac12\qty(\grade[k±2]{Aσ} - \grade[k±2]{σA})
	.\end{align}
	However,
	\begin{math}
		\grade[k±2]{σA} = \revsign{k ± 2}\grade[k ± 2]{\rev{A}\rev{σ}} = -\revsign{k ± 2}\revsign{k}\grade[k ± 2]{Aσ}
	\end{math}
	and the reversion signs\sidenote{
		Recall from \cref{eqn:reversion-sign} that $\rev{A} = \revsign{k}A$ for a $k$-vector where
		\begin{math}
			\revsign{k} = (-1)^{\frac{(k - 1)k}2}
		.\end{math}
	} satisfy $s_{k±2}s_k = -1$ for any $k$.
	Hence, $\grade[k±2]{A×σ} = 0$, leaving only the grade $k$ part, $A × σ = \grade[k]{A × σ}$.
\end{proof}
A corollary of \cref{lem:bivector-comm-grade-preserving} is that the commutator is closed on the space of bivectors, $\GA[2]$.
Clearly \cref{eqn:commutator-prod} is bilinear and satisfies the Jacobi identity, so $\GA[2]$ in fact forms a Lie algebra with the bivector commutator $×$ as the Lie bracket.

Because the even subalgebra $\GA[+] \supset \GA[2]$ is closed under the geometric product, the exponential
\begin{math}
	e^σ = 1 + σ + \frac12 σ^2 + \cdots
\end{math}
of a bivector is an even multivector.
Furthermore, note that the reverse $\rev{(e^σ)} = e^{(\rev{σ})} = e^{-σ}$ is the inverse, and also that $e^σ$ is continuously connected to the identity by the path $e^{λσ}$ for $λ ∈ [0, 1]$.
Therefore, $e^σ ∈ \op{Spin}^+$ is a rotor, and we have a Lie algebra--Lie group correspondence shown in \cref{fig:bivector-liealg}.
Thus, both the rotor groups and their Lie algebras are directly represented within the mother algebra $\GA(p, q)$.

\begin{figure}[h]
	\centering
	\begin{tikzcd}[column sep=small]
		\op{Spin}^+(p, q) & \SO^+(p, q) \\
		\GA[2](p, q) & \liealg{so}(p, q)
		\arrow["\exp"{description}, thin, from=2-1, to=1-1]
		\arrow["\cong"{description}, draw=none, from=2-1, to=2-2]
		\arrow["\exp"{description}, thin, from=2-2, to=1-2]
		\arrow[two heads, thin, from=1-1, to=1-2]
	\end{tikzcd}
	\caption{
		The Lie algebras $\liealg{so}(p, q)$ and $\GA[2](p, q)$ under $×$ are isomorphic, and are associated respectively to $\SO^+(p, q)$ and its universal double cover $\op{Spin}^+(p, q)$.
	}
	\label{fig:bivector-liealg}
\end{figure}





\section{Higher Notions of Orthogonality}
\label{sec:higher-orthogonal}

As discussed at the start of this chapter, the lack of a $\ZZ$-grading means that a geometric product of blades is generally an inhomogeneous multivector.
Geometrically, the grade $k$ part of product of blades reveals the degree to which the two blades are `orthogonal' or `parallel', in a certain $k$-dimensional sense.

To see this, first consider the special case where the product of blades $a$ and $b$ is a homogeneous $k$-blade.
This occurs when there exists a common orthonormal basis $\qty{𝒆_i}$ such that
\begin{align}
	a &= α \etc{\ve_{i_\i}}{}p
&	&\text{ and }
&	b &= β \etc{\ve_{j_\i}}{}q
\end{align}
simultaneously, for scalars $α,β$.
Then, the product is
\begin{align}
	ab = ±αβ \etc{\ve_{h_\i}}{}k
.\end{align}
Each pair of parallel basis vectors in $a$ and $b$ contributes an overall factor of $\ve_i^2 = ±1$, and each transposition required to bring each pair together flips the overall sign.

The resulting grade $k$ is the number of basis vectors $𝒆_{h_i}$ which are not common to both $a$ and $b$; i.e., $\set{h_i}$ is the symmetric difference of $i$ and $j$.
% $\set{\etc{i_\i},p} \ominus \set{\etc{j_\i},q}$.
Thus, the possible values of $k$ are separated by steps of two, with the maximum $k = p + q$ attained when no basis vectors are common to $a$ and $b$.
In terms of the spans of the blades, we have
\begin{align}
	k &= \underbrace{\dim\spanof{a}}_p + \underbrace{\dim\spanof{b}}_q - \underbrace{2\dim(\spanof{a}∩\spanof{b})}_{2m}
% \\	&= p + q - 2m
\\	&∈ \qty{|p - q|, |p - q| + 2, …, p + q - 2, p + q}
	\label{eqn:possible-grades}
.\end{align}
Solving for the dimension of the intersection, we have
\begin{align}
	m = \frac12\qty(p + q - k)
.\end{align}
Thus, the higher the grade $k$ of the product $ab$, the lower the dimension $m$ of the intersection of their spans.



We are used to the geometric meaning of two vectors being parallel or orthogonal.
In terms of vector spans, they imply that the intersection is one or zero dimensional, respectively.
Similarly, blades of higher grade can be `parallel' or `orthogonal' to varying degrees, depending on the dimension of their intersection, $m$.

For example, the intersection of two $2$-blades may be of dimension two, one or (in four or more dimensions) zero.
The notion of parallel (i.e., being a scalar multiple) remains clear ($m = 2$), but there are now two different types of orthogonality for 2-blades ($m = 1$ and $m = 0$).
An example of the first type can be pictured as two planes meeting at right-angles along a line; the second type requires at least four dimensions.


\begin{definition}
	\label{def:Δ-orthogonal}
	A $p$-blade $a$ and $q$-blade $b$ satisfying $ab = \grade[k]{ab}$ are called \textdef{$Δ$-orthogonal} where $Δ = \frac12(k - |p - q|)$.
\end{definition}

Informally, $Δ$-orthogonality of $a$ and $b$ means that $ab$ is of the $Δ$th grade above the minimum possible grade $|p - q|$.
The higher $Δ$, the fewer linearly independent directions are shared by (the spans of) $a$ and $b$.
Different cases are exemplified in \cref{tbl:blade-product-interpretations}.

\begin{table*}
	% \centering
	\renewcommand{\arraystretch}{1.15}
	\begin{tabular}{CCCCCCcl}
		p & q & k & \grade[k]{ab} & Δ & m & \emph{commutativity} & \emph{geometric interpretation of $ab = \ip{ab}_k$}
	% \\[1ex]	\hline
	\\[2pt]	\hline\hline
		1 & 1 & 0 & a \fatdot b   & 0 & 1 & commuting     & vectors are parallel; $a \parallel b ⟺ a = λb$
	\\	1 & 1 & 2 & a∧b           & 1 & 0 & anticommuting & vectors are orthogonal $a \perp b$
	\\	\hline
		2 & 2 & 0 & a \fatdot b   & 0 & 2 & commuting     & bivectors are parallel $a = λb$
	\\	2 & 2 & 2 & a×b           & 1 & 1 & anticommuting & bivectors are at right-angles to each other
	\\	2 & 2 & 4 & a∧b           & 2 & 0 & commuting     & bivectors are \emph{$2$-orthogonal}
	\\	\hline
		1 & 2 & 1 & a \fatdot b   & 0 & 1 & anticommuting & vector $a$ lies in plane of bivector $b$
	\\	1 & 2 & 3 & a∧b           & 1 & 0 & commuting     & vector $a$ is normal to plane of bivector $b$
	\\	\hline
		2 & 3 & 1 & a \fatdot b   & 0 & 2 & commuting     & bivector $a$ lies in span of trivector $b$
	\\	2 & 3 & 3 & \grade[3]{ab} & 1 & 1 & anticommuting & $a$ and $b$ are \emph{$1$-orthogonal}
	\\	2 & 3 & 5 & a∧b           & 2 & 0 & commuting     & $a$ and $b$ are \emph{$2$-orthogonal}
	% \\	\hline
	% 	3 & 3 & 0 & a \fatdot b   & 0 & 3 & commuting     & trivectors are $0$-orthogonal
	% \\	3 & 3 & 2 & \grade[2]{ab} & 1 & 2 & anticommuting & trivectors are $1$-orthogonal
	% \\	3 & 3 & 4 & \grade[4]{ab} & 2 & 1 & commuting     & trivectors are $2$-orthogonal
	% \\	3 & 3 & 6 & a∧b           & 3 & 0 & anticommuting & trivectors are $3$-orthogonal
	\end{tabular}
	\caption{
		Geometric interpretation of the $k$-blade $ab = \grade[k]{ab}$ where $a$ and $b$ are of grades $p$ and $q$ respectively, and where $m = \dim(\spanof a ∩ \spanof b)$.
	}
	\label{tbl:blade-product-interpretations}
\end{table*}


Familiarity with some special cases may aid intuition when considering general products of blades.
For instance, if the product of two bivectors is $σ_1σ_2 = σ_1·σ_2 + σ_1×σ_2$, then it is understood that $σ_1$ has a component parallel to $σ_2$, and a component which meets $σ_2$ at right-angles along a line of intersection.
\begin{marginfigure}
	\includefigure{orthogonality}
	\caption{$\set{ρ, ω}$ are $1$-orthogonal ($ρω = ρ×ω$) and $\set{σ, ρ}$ have both $0$- and $1$-orthogonal components ($σρ = σ \fatdot ρ + σ × ρ$).}
	\label{fig:orthogonal}
\end{marginfigure}
In other words, $σ_1$ and $σ_2$ are planes that intersect along a line with some angle between them (see \cref{fig:orthogonal}).
On the other hand, if $σ_1σ_2 = σ_1∧σ_2$, then the bivectors exist in orthogonal planes --- a scenario requiring at least four dimensions.




\section{More Graded Products}
\label{sec:more-graded-prods}

All operations in the geometric algebra can be expressed in terms of the fundamental geometric product along with grade projection operators $\grade[k]{\phantom{A}}$.
For example, we have seen that the wedge and inner products ($∧$ and $\fatdot$ of \cref{def:wedge-and-fat-dot-for-multivectors}) are merely combinations of multiplication and projection.

There are other similar constructions which are useful enough warrant their own definitions, including the left and right \emph{contractions}.
\begin{definition}
	% For any multivectors $A$ and $B$, define the
	\begin{align}
		&\text{\textdef{left contraction}}
	&	A \lcontr B &= \sum_{p,q}\grade[q - p]{\grade[p]{A}\grade[q]{B}}
	\\	&\text{\textdef{right contraction}}
	&	A \rcontr B &= \sum_{p,q}\grade[p - q]{\grade[p]{A}\grade[q]{B}}
	\end{align}
	% products.
\end{definition}
We declare the various products $·$, $∧$, $\lcontr$ and $\rcontr$ to have \emph{higher} precedence than the geometric product (aligning with \cite[§2.5]{doran2003ga}), so that we may write e.g., $A·B\,C = (A·B)C$ and $𝒖∧𝒗 \, \vol = (𝒖∧𝒗)\vol$ unambiguously.

Observe that $\rev{(A\lcontr B)} = \rev{A}\rcontr\rev{B}$, so these are in essentially the same operation --- only one is viewed in a mirror.\sidenote{
	I.e., every statement involving $\lcontr$ produces, under reversion, an equivalent statement involving $\rcontr$.
}

The fat dot product reduces to a contraction on homogeneous multivectors, depending on which multivector has the higher grade.
If $A$ is a $p$-vector and $B$ a $q$-vector, then
\begin{align}
	A \fatdot B =
	\begin{cases}
		A \lcontr B & p ≤ q
	\\	A \rcontr B & q ≥ p
	\end{cases}
,\end{align}
with $A \fatdot B = A \lcontr B = A \rcontr B = \grade{AB}$ when $p = q$.
While in some expressions the grades of multivectors are obvious so that it is clear how the fat dot product acts, the contractions are arguably better behaved algebraically: the conditional comparison of grades is reincorporated into the products themselves, allowing for more useful identities to be written with fewer grade-based exceptions \cite{dorst2002inner-products}.\sidenote{
	E.g., $𝒖 A = 𝒖 \fatdot A + 𝒖 ∧ A$ holds if $A$ has zero scalar part, but $𝒖 A = 𝒖 \lcontr A + 𝒖 ∧ A$ holds for \emph{any} $A$.
}


\begin{lemma}
	\label{lem:contr-and-wedge-by-vector}
	For any vector $𝒖$ and multivector $A$,
	\begin{align}
		𝒖 \lcontr A &= \frac12\qty(𝒖A - \invol{A}𝒖)
	,&	𝒖 ∧ A &= \frac12\qty(𝒖A + \invol{A}𝒖)
	.\end{align}
\end{lemma}
\begin{proof}
	Begin by assuming $A$ is of grade $k$.
	The geometric product contains two grades,
	\begin{align}
		𝒖A = \grade[k - 1]{𝒖A} + \grade[k + 1]{𝒖A}
		≡ 𝒖 \lcontr A + 𝒖 ∧ A
	.\end{align}
	Now consider the reversed product, and rearrange terms using the fact that $\rev{a} = \revsign{p}a$ if $a$ is a $p$-vector.
	\begin{align}
		A𝒖 &= A \rcontr 𝒖 + A ∧ 𝒖
	\\	&= \revsign{k - 1}\; \rev{𝒖} \lcontr \rev{A}
		+ \revsign{k + 1}\; \rev{𝒖} ∧ \rev{A}
	\\	&= \revsign{k - 1}\revsign{k}\; 𝒖 \lcontr A
		+ \revsign{k + 1}\revsign{k}\; 𝒖 ∧ A
	\end{align}
	With reference to \cref{eqn:reversion-sign}, notice that $\revsign{k ± 1}\revsign{k} = ±(-1)^k$.
	Thus,
	\begin{align}
		\invol{A}𝒖 = (-1)^kA𝒖 = -𝒖 \lcontr A + 𝒖 ∧ A
	.\end{align}
	Taking the sum and difference of $𝒖A$ and $\invol{A}𝒖$ as above yields the two results, respectively --- at least for homogeneous $A$.
	Since the expressions are linear in $A$, and are written without reference to $k$, they extend by linearity to general multivectors.
\end{proof}


\begin{corollary}
	\label{lem:lcontr-antideriv}
	Contraction by a vector is an anti-derivation;
	\begin{align}
		𝒖 \lcontr (AB) = (𝒖 \lcontr A)B + \invol{A}(𝒖 \lcontr B)
	.\end{align}
\end{corollary}
\begin{proof}
	By using \cref{lem:contr-and-wedge-by-vector} to rewrite the contraction, the result follows immediately.
	\begin{align}
		𝒖 \lcontr (AB)
		&= \frac12(𝒖AB - \invol{(AB)} 𝒖)
	\\	&= \frac12(𝒖AB - \invol{A} 𝒖B + \invol{A} 𝒖B - \invol{A} \invol{B} 𝒖)
	\\	&= (𝒖 \lcontr A)B + \invol{A} (𝒖 \lcontr B)
	\end{align}
	This also implies that vector contraction is an anti-derivation with respect to the wedge product, i.e., $𝒖 \lcontr (A ∧ B) = (𝒖 \lcontr A) ∧ B + \invol{A} ∧ (𝒖 \lcontr B)$.
\end{proof}


\begin{lemma}
	For a bivector $σ$ and multivector $A$,
	\begin{align}
		σA = σ \lcontr A + σ × A + σ ∧ A
	,\end{align}
	where $a×b = \frac12(ab - ba)$ is the commutator product.
\end{lemma}
\begin{proof}
	Suppose $A$ is a $k$-vector.
	The geometric product with a bivector then contains non-zero parts of three grades,
	\begin{align}
		σA &= \grade[k - 2]{σA} + \grade[k]{σA} + \grade[k + 2]{σA}
		≡ σ \lcontr A + \grade[k]{σA} + σ ∧ A
	.\end{align}
	Consider the reverse product,
	\begin{align}
		Aσ &= A \rcontr σ + \grade[k]{Aσ} + A ∧ σ
	\intertext{and reverse each term, noting that $\rev{σ} = -σ$ and $\rev{A} = \revsign{k}A$,}
		% &= \revsign{k - 2}\; \rev{σ} \lcontr \rev{A} + \revsign{k}\; \grade[k]{\rev{σ}\rev{A}} + \revsign{k + 2}\; \rev{σ} ∧ \rev{A}
		&= -\revsign{k}\qty(\revsign{k - 2}\; σ \lcontr A + \revsign{k}\; \grade[k]{σA} + \revsign{k + 2}\; σ ∧ A)
	\intertext{simplifying with $\revsign{k}\revsign{k ± 2} = -1$.}
		&= σ \lcontr A - \grade[k]{σA} + σ ∧ A
	\end{align}
	Thus,
	\begin{math}
		\grade[k]{σA} = \frac12(σA - Aσ) ≡ σ × A
	,\end{math}
	and so the result holds for homogeneous multivectors, and by linearity for general multivectors.
\end{proof}

% \notebefore{
\begin{lemma}
	\label{lem:triangular-range-cyclicity}
	For $i,j,k ≥ 0$, the following conditions are equivalent.
	\begin{align}
		|i - j| &≤ k ≤ i + j
	,&	|k - i| &≤ j ≤ k + i
	,&	|j - k| &≤ i ≤ j + k
	.\end{align}
\end{lemma}
% }{
\begin{proof}%[Proof of \cref{lem:triangular-range-cyclicity}]
	There exists a triangle in the Euclidean plane with side lengths $i, j, k$ if and only if $|i - j| ≤ k ≤ i + j$.
	By relabelling its sides, it follows that the other relations are equivalent.
\end{proof}
% }



% \notebefore{
\begin{lemma}
	\label{lem:graded-product-triangular-range}
	The three terms
	\begin{align}
		&\grade[k]{\grade[p]{A}\grade[q]{B}}
	,&	&\grade[q]{\grade[k]{A}\grade[p]{B}}
	,&	&\grade[p]{\grade[q]{A}\grade[k]{B}}
	\end{align}
	all vanish unless $|p - q| ≤ k ≤ p + q$.
\end{lemma}
% }{
\begin{proof}%[Proof of \cref{lem:graded-product-triangular-range}]
	From \cref{eqn:possible-grades} it follows that 
	\begin{math}
		\grade[k]{\grade[p]{A}\grade[q]{B}} ≠ 0
	\end{math}
	implies
	\begin{math}
		|p - q| ≤ k ≤ p + q
	.\end{math}
	By lemma \ref{lem:triangular-range-cyclicity}, it also holds under permutations of the grade projections.
\end{proof}
% }



\begin{lemma}
	For any multivectors $A, B, C$,
	\begin{align}
		(A \rcontr B) \rcontr C &= A \rcontr (B ∧ C)
	,&	A \lcontr (B \lcontr C) &= (A ∧ B) \lcontr C
	.\end{align}
\end{lemma}
\begin{proof}
	It suffices to derive the identities for homogeneous multivectors; they extend by linearity to general multivectors.
	Thus, let $(A, B, C)$ be multivectors of grade $(a, b, c)$, respectively.


	Consider 
	\begin{math}
		\grade[a - b - c]{\grade[k]{AB}C}
	\end{math}
	and assume it to be non-zero.
	By lemma \ref{lem:graded-product-triangular-range}, this is zero unless $k ≤ c + (a - b - c) = a - b$.
	However, $\grade[k]{AB}$ is zero unless $|a - b| ≤ k$, hence $k = a - b$.
	Therefore,
	\begin{align}
		\grade[a - b - c]{(AB)C}
		= \grade[a - b - c]{\grade[a - b]{AB}C}
	,\end{align}
	since the only non-zero contribution from the product $AB$ is the part of grade $a - b$.

	Similarly, assume that
	\begin{math}
		\grade[a - b - c]{A\grade[k]{BC}}
	\end{math}
	is non-zero.
	Again by lemma~\ref{lem:graded-product-triangular-range} we have $|a - (a - b - c)| ≤ k$ implying $b + c ≤ k$.
	Since $\grade[k]{BC}$ is zero unless $k ≤ b + c$, we have $k = b + c$ exactly and
	\begin{align}
		\grade[a - b - c]{A(BC)}
		= \grade[a - b - c]{A\grade[b + c]{BC}}
	.\end{align}

	By associativity of the geometric product, we have shown
	\begin{align}
		\grade[(a - b) - c]{\grade[a - b]{AB}C}
		= \grade[a - (b + c)]{A\grade[b + c]{BC}}
	,\end{align}
	which is definitionally equivalent to
	\begin{align}
		(A \rcontr B) \rcontr C = A \rcontr (B ∧ C)
	.\end{align}
	Reversion yields the corresponding identity for left contraction.
\end{proof}


To summarise these results, for \emph{any} multivectors $(A, B, C)$, we have
\begin{align}
	(A \rcontr B) \rcontr C &= A \rcontr (B ∧ C)
,&	A \lcontr (B \lcontr C) &= (A ∧ B) \lcontr C
,\\	(A \lcontr B) \rcontr C &= A \lcontr (B \rcontr C)
,&	𝒖 \bullet (B \bullet 𝒗) &= (𝒖 \bullet B) \bullet 𝒗
.\end{align}
The last equation is a specialisation of the lower left, which in particular means that parentheses are unnecessary when defining the components of a bivector $F = F^{ij}\ve_i∧\ve_j$ with the expression
\begin{math}
	F_{ij} = \ve_i \bullet F \bullet \ve_j
.\end{math}


