\chapter{Preliminary Theory}
\label{cha:preliminary-theory}


Many of the tools we will develop take place in various associative algebras.
As well as the geometric algebra of spacetime, we will encounter tensors, exterior forms, quaternions, and other structures in this category.
Instead of defining each algebra axiomatically as needed, it is easier to develop the general theory of associative algebras, taking special 
This enables the use of the same tools and the same terminology throughout.

Therefore, this section is an overview of the abstract theory of associative algebras, which more generally belongs to \emph{ring theory}.\sidenote{
	A \textdef{ring} is a field without the requiring commutativity nor existence of multiplicative inverses.
}
\emph{Algebras}, \emph{quotients} and \emph{gradings} are defined, as well as \emph{tensors}, \emph{multivectors} and \emph{exterior forms}.
Most definitions in this chapter can be readily generalised by replacing the field $\FF$ with a ring.
The excitable reader may skip this chapter and refer back as needed.


\section{Associative Algebras}

Throughout, $\FF$ denotes the underlying field of some vector space.
(Eventually, $\FF$ will always be taken to be $\RR$, but we may begin in generality.)
\begin{definition}
	\label{def:associative-algebra}
	An \textdef{associative algebra} $A$ is a vector space equipped with a product $âŠ› : A Ã— A \to A$ which is associative and bilinear.
\end{definition}
Associativity means $(a âŠ› b) âŠ› c = a âŠ› (b âŠ› c)$ for $a,b,c âˆˆ A$, while bilinearity means the product is:
\marginnote{
	\emph{Examples.}
	Any ring forms an associative algebra when considered as a one-dimensional vector space.
	The complex numbers can be viewed as a real $2$-dimensional algebra by defining $âŠ›$ to be complex multiplication;
	\begin{math}
		(x_1, y_1)âŠ›(x_2, y_2) â‰” (x_1x_2 - y_1y_2, x_1y_2 + y_1x_2)
	.\end{math}
}
\begin{itemize}
	\item compatible with scalars: $(Î»a) âŠ› b = a âŠ› (Î»b) = Î»(a âŠ› b)$ for $Î» \in \FF$; and
	\item distributive over addition: $(a + b) âŠ› c = a âŠ› c + b âŠ› c$, and similarly for $a âŠ› (b + c)$.
\end{itemize}
This definition can be generalised by relaxing associativity or by letting $\FF$ be a ring.
However, we will use ``algebra'' exclusively to mean an associative algebra over a field (usually $\RR$).




\subsubsection{The free tensor algebra}

The most general (associative) algebra containing a given vector space $V$ is the \textdef{tensor algebra $\TA{V}$}.
The tensor product $âŠ—$ satisfies exactly the relations of \cref{def:associative-algebra} with no others.
Thus, the tensor algebra associative, bilinear and \emph{free} in the sense that no further information is required in its definition.

As a vector space, the tensor algebra is equal to the infinite direct sum
\begin{align}
	\label{eqn:tensor-algebra-graded-decomposition}
	\TA{V} â‰… \bigoplus_{k=0}^âˆ V^{âŠ—k} â‰¡ \FF âŠ• V âŠ• (V âŠ— V) âŠ• (V âŠ— V âŠ— V) âŠ• \cdots
\end{align}
where each $\TA[k]{V}$ is the subspace of \textdef{tensors of grade $k$}.

\subsection{Quotient algebras}

Owing to the maximal generality of the free tensor algebra, any other associative algebras may be constructed as a \emph{quotient} of $\TA{V}$.
In order for a quotient $\quot{\TA{V}}{\sim}$ to itself form an algebra, the equivalence relation $\sim$ must preserve the associative algebra structure.
\begin{definition}
	\label{def:congruence}
	A \textdef{congruence} on an algebra $A$ is an equivalence relation $\sim$ which is compatible with the algebraic relations, so that if $a \sim a'$ and $b \sim b'$ then $a + b \sim a' + b'$ and $aâŠ›b \sim a'âŠ›b'$.
\end{definition}
The quotient of an algebra by a congruence naturally has the structure of an algebra, and so is called a \textdef{quotient algebra}.
\begin{lemma}
	\label{thm:quotient-algebra-by-congruence}
	The \textdef{quotient} $\quot A {\sim}$ of an algebra $A$ by a congruence $\sim$, consisting of equivalence classes $[a] \in \quot A {\sim}$ as elements, forms an algebra with the naturally inherited operations $[a] + [b] â‰” [a + b]$ and $[a]âŠ›[b] â‰” [aâŠ›b]$.
\end{lemma}
\begin{proof}
	The fact that the operations $+$ and $âŠ›$ of the quotient are well-defined follows from the structure-preserving properties of the congruence.
	Addition is well-defined if $[a] + [b]$ does not depend on the choice of representatives: if $a' âˆˆ [a]$ then $[a'] + [b]$ should be $[a] + [b]$.
	By congruence, we have from $a \sim a'$ so that $[a + b] = [a' + b]$ and indeed $[a] + [b] = [a'] + [b]$.
	Likewise for $âŠ›$.
\end{proof}

Instead of presenting an equivalence relation, it is often easier to define a congruence by specifying the set of elements which are equivalent to zero, from which all other equivalences follow from the algebra axioms.
Such a set of all `zeroed' elements is called an ideal.
\begin{definition}
	\label{def:ideal}
	A \textdef{(two-sided) ideal} of an algebra $A$ is a subset $I \subseteq A$ which is closed under addition and invariant under multiplication, so that
	\begin{itemize}
		\item if $a, b âˆˆ I$ then $a + b âˆˆ I$; and
		\item if $r âˆˆ A$ and $a âˆˆ I$ then $râŠ›a âˆˆ I âˆ‹ aâŠ›r$.
	\end{itemize}
\end{definition}

We will use the notation $I = \gen{a_i}$ to mean the ideal generated by the relations $a_i \sim 0$.
For example, $\gen{a} = \spanof{r âŠ› a âŠ› r' | r, r' âˆˆ A}$ is the ideal consisting of sums of products involving the zeroed element $a$.
$\gen{ğ’– âŠ— ğ’– | ğ’– âˆˆ V}$, or simply $\gen{ğ’–âŠ—ğ’–}$, is the ideal in $\TA{V}$ consisting of sums of terms of the form $a âŠ— ğ’– âŠ— ğ’– âŠ— b$ for vectors $ğ’–$ and arbitrary $a, b âˆˆ \TA{V}$.


\begin{lemma}
	\label{lem:congruence-ideal-equiv}
	An ideal uniquely defines a congruence, and vice versa, by the identification of $I$ as the set of zero elements,
	\begin{math}
		a âˆˆ I \iff a \sim 0
	.\end{math}
\end{lemma}
\begin{proof}
	If $\sim$ is a congruence, then $I â‰” \set{a | a \sim 0}$ is an ideal because it is closed under addition (if $a, b âˆˆ I$ then $a + b \sim 0 + 0 = 0$ so $a + b âˆˆ I$) and invariant under multiplication (for any $a âˆˆ I$ and $r âˆˆ A$, we have $râŠ›a \sim râŠ›0 = 0 = 0âŠ›r \sim aâŠ›r$).

	Conversely, if $I$ is an ideal, then we show that $\sim$ defined by $a \sim b âŸº a - b âˆˆ I$ is a congruence.
	Let $a \sim a'$ and $b \sim b'$.
	Both addition
	\begin{align}
		\begin{aligned}
			a - a' &âˆˆ I
		\\	b - b' &âˆˆ I
		\end{aligned}
		\;\Bigg\}
		\implies
		(a + b) - (a' + b') âˆˆ I
		\iff
		a + b \sim a' + b'
	\end{align}
	and multiplication
	\begin{align}
		\begin{aligned}
			(a - a')âŠ›b &âˆˆ I
		\\	a'âŠ›(b - b') &âˆˆ I
		\end{aligned}
		\;\Bigg\}
		\implies
		aâŠ›b - a'âŠ›b' âˆˆ I
		\iff
		aâŠ›b \sim a'âŠ›b'
	\end{align}
	are respected, so $\sim$ is a congruence.
\end{proof}

The equivalence of ideals and congruences is a general feature of abstract algebra.\sidenote{
	E.g., in group theory, ideals are \emph{normal subgroups} and define congruences, which are equivalence relations satisfying $gag^{-1} \sim \op{id}$ whenever $a \sim \op{id}$.
	% A group modulo a normal subgroup forms a quotient group.
}
Furthermore, both can be given in terms of a homomorphism between algebras,\sidenote{
	A \emph{homomorphism} is a structure-preserving map; in the case of algebras, a linear map $Î¨ : A â†’ A'$ which satisfies $Î¨(aâŠ›b) = Î¨(a)\mathrel{âŠ›'}Î¨(b)$.
} and this is often the most convenient way to define a quotient.
\begin{theorem}[first isomorphism theorem]
	\label{thm:first-iso}
	If $Î¨ : A â†’ B$ is a homomorphism, between algebras, then
	\begin{enumerate}
		\item the relation $a \sim a'$ defined by $Î¨(a) = Î¨(a')$ is a congruence;
			\label{item:first-iso:cong}
		\item the kernel $I â‰” \ker Î¨$ is an ideal; and
			\label{item:first-iso:ker}
		\item the quotients $\quot{A}{\sim} â‰¡ \quot{A}{I} â‰… Î¨(A)$ are all isomorphic.
			\label{item:first-iso:iso}
	\end{enumerate}
\end{theorem}
\begin{proof}
	We assume $A$ and $B$ associative algebras.
	(For a proof in universal algebra, see \cite[Â§15]{gallian2021abstract-algebra}.)

	To verify \cref{item:first-iso:cong}, suppose that $Î¨(a) = Î¨(a')$ and $Î¨(b) = Î¨(b')$ and note that $Î¨(a + a') = Î¨(b + b')$ by linearity and $Î¨(aâŠ›b) = Î¨(a'âŠ›b')$ from $Î¨(aâŠ›b) = Î¨(a)âŠ›Î¨(b)$, so the congruence properties of \cref{def:congruence} are satisfied.

	For \cref{item:first-iso:ker}, note that $\ker Î¨$ is a vector subspace, and that $a âˆˆ \ker Î¨$ implies $aâŠ›r âˆˆ \ker Î¨$ for any $r âˆˆ A$ since $Î¨(aâŠ›r) = Î¨(a)âŠ›Î¨(r) = 0$.
	Thus, $\ker Î¨$ is an ideal by \cref{def:ideal}.

	The first equivalence in \cref{item:first-iso:iso} follows from \cref{lem:congruence-ideal-equiv}.
	For an isomorphism $Î¦ : \quot A {\ker Î¨} â†’ Î©(A)$, pick $Î¦([a]) = Î¨(a)$.
	This is well-defined because the choice of representative of the equivalence class $[a]$ does not matter; $a \sim a'$ if and only if $Î¨(a) = Î¨(a')$ by definition of $\sim$, which simultaneously shows that $Î¦$ is injective.
	Surjectivity follows since any element of $Î¨(A)$ is of the form $Î¨(a)$ which is the image of $[a]$.
\end{proof}


With the free tensor algebra and \cref{thm:first-iso} in hand, we are able to describe any associative algebra as a quotient of the form $\quot{\TA{V}}{I}$.

\begin{definition}
	The \textdef{dimension} $\dim A$ of a quotient algebra $A = \quot {\TA{V}} I$ is its dimension as a vector space.
	The \textdef{base dimension} of $A$ is the dimension of the underlying vector space $V$.
\end{definition}
Algebras of finite base dimension may be infinite-dimensional, as is the case for the tensor algebra itself (which is a quotient by the trivial ideal).



\subsection{Graded algebras}

Associative algebras may possess another layer of useful structure: a grading.
An example grading for the tensor algebra has already been exhibited in \cref{eqn:tensor-algebra-graded-decomposition}.
Gradings generalise the \emph{degree} or \emph{rank} of tensors or forms, and the notion of \emph{parity} (even/oddness) for functions or polynomials.

Informally, an algebra's grading provides a labelling for some of its elements, such that labels are combined simply (usually by addition) under the algebra's multiplication.

\begin{definition}
	\label{def:grading}
	An algebra $A$ is \textdef{$R$-graded} for $(R, +)$ a monoid\,\sidenote{A \textdef{monoid} is a group without the requirement of inverses; i.e., a set with an associative binary operation for which there is an identity element.} if there exists a decomposition
	\begin{align}
		A = \bigoplus_{k âˆˆ R} A_{k}
	\end{align}
	such that $A_{i} âŠ› A_{j} âŠ† A_{i + j}$, i.e., $a âˆˆ A_{i}, b âˆˆ A_{j} âŸ¹ a âŠ› b âˆˆ A_{i + j}$.
\end{definition}
The monoid is usually taken to additive over $\NN$ or $\ZZ$, possibly modulo some integer.
For instance, the tensor algebra $\TA{V}$ is $\NN$-graded, since if $a âˆˆ \TA[p]{V}$ and $b âˆˆ \TA[q]{V}$ then $a âŠ— b âˆˆ \TA[p + q]{V}$.
Indeed, $\TA{V}$ is also $\ZZ$-graded if for $k < 0$ we understand $\TA[k]{V} â‰” \qty{\mathbf{0}}$ to be the trivial vector space.
The tensor algebra is also $\ZZ_p$-graded, where $\ZZ_p â‰¡ \quot \ZZ {p\ZZ}$ is addition modulo any $p > 0$, since the decomposition
\begin{align}
	\TA{V} = \bigoplus_{k = 0}^{p - 1} Z_k
	\qqtext{where}
	Z_k = \bigoplus_{n = 0}^âˆ \TA[k + np]{V}
		= \TA[k]{V} âŠ• \TA[(k + p)]{V} âŠ• \cdots
\end{align}
satisfies $Z_i âŠ— Z_j \subseteq Z_k$ when $k â‰¡ i + j \mod p$.
In particular, $\TA{V}$ is $\ZZ_2$-graded,\sidenote{
	Algebras which are $\ZZ_2$-graded are sometimes called \emph{superalgebras}, with the prefix `super-' originating from supersymmetry theory.
} and its elements admit a notion of \emph{parity}: elements of $Z_0 = \FF âŠ— \TA[2]{V} âŠ— \cdots$ are even, while elements of $Z_1 = V âŠ— \TA[3]{V} âŠ— \cdots$ are odd, with parity is respected by $âŠ—$ as it is for the integers.

Just as not all functions $f : \RR â†’ \RR$ are even or odd, not all elements of a $\ZZ_2$-graded algebra are even or odd.
More generally, not all elements of a graded algebra belong to a single graded subspace.


\subsubsection{Graded derivations}

Derivative-like operators which obey the product rule enjoy the algebraic properties of a \emph{derivation}.
In graded algebras, operators can also obey a `graded product rule'.

\begin{definition}
	A \textdef{$d$-derivation} or \textdef{derivation of grade $d$} on a graded algebra $(A, âŠ›)$ is a linear operator $\DD$ satisfying
	\begin{align}
		\label{eqn:graded-derivation}
		\DD(a âŠ› b) = (\DD a) âŠ› b + (-1)^{dk} a âŠ› (\DD b)
	\end{align}
	for all $a âˆˆ A_k$ and $b âˆˆ A$.
\end{definition}

A \textdef{derivation} is short for a $0$-derivation, always obeying
\begin{math}
	\DD(a âŠ› b) = (\DD a) âŠ› b + a âŠ› (\DD b)
;\end{math}
and an \textdef{anti-derivation} is short for a $1$-derivation.

\begin{lemma}
	\label{lem:coms-of-derivations}
	If $\DD_1$ and $\DD_2$ are derivations of degree $d_1$ and $d_2$, respectively, then the commutator $[\DD_1, \DD_2] = \DD_1\DD_2 - \DD_2\DD_1$ is a $(d_1 + d_2)$-derivation if and only if $a + b$ is even.
	Similarly for the anti-commutator $\qty{\DD_1, \DD_2} = \DD_1\DD_2 + \DD_2\DD_1$, only instead when $d_1 + d_2$ is odd.
\end{lemma}
\begin{proof}
	By unpacking $[\DD_1, \DD_2](a âŠ› b)$ and applying \cref{eqn:graded-derivation}, we see that the last unwanted term in
	% \begin{fullwidth}
	\begin{align}
		[\DD_1, \DD_2](a âŠ› b)
		&= ([\DD_1, \DD_2] a) âŠ› b
		+ (-1)^{(a+b)k}a âŠ› ([\DD_1, \DD_2] b)
	% \\	+ \qty((-1)^{bk} - (-1)^{ak})(\DD_1 a) âŠ› (\DD_2 b)
		% + \qty((-1)^{ak} - (-1)^{bk})(\DD_2 a) âŠ› (\DD_1 b)
	\\	&- \qty((-1)^{ak} - (-1)^{bk})\qty((\DD_1 a) âŠ› (\DD_2 b) - (\DD_2 a) âŠ› (\DD_1) b)
	\end{align}
	% \end{fullwidth}
	vanishes when $(-1)^a - (-1)^b = 0$, or when $d_1 + d_2$ is even.
	The computation for $\qty{\DD_1, \DD_2}$ is identical except that the unwanted term involves $(-1)^a + (-1)^b$ rather than a difference, vanishing when $d_1 + d_2$ is odd.
\end{proof}


\subsubsection{Graded quotient algebras}

A grading structure may or may not be inherited by a quotient --- in particular, not all quotients of $\TA{V}$ inherit its $\ZZ$-grading.
When reasoning about quotients of graded algebras, the following fact is useful.
\begin{lemma}
	\label{lem:quotients-commute-with-direct-sums}
	Quotients commute with direct sums, so if
	\begin{align}
		A = \bigoplus_{k âˆˆ R} A_k
		\qqtext{and}
		I = \bigoplus_{k âˆˆ R} I_k
		\qqtext{then}
		\quot A I = \bigoplus_{k âˆˆ R} (\quot{A_k}{I_k})
	\end{align}
	where $R$ is some index set.
\end{lemma}
\begin{proof}
	It is sufficient to prove the case for direct sums of length two.
	We then seek an isomorphism
	\begin{math}
		Î¦ : \quot{(A âŠ• B)}{(I âŠ• J)} â†’ (\quot{A}{I}) âŠ• (\quot{B}{J})
	.\end{math}
	Elements of the domain are equivalence classes of pairs $[(a, b)]$ with respect to the ideal $I âŠ• J$.
	The direct sum ideal $I âŠ• J$ corresponds to the congruence defined by $(a, b) \sim (a', b') \iff a \sim a'$ and $b \sim b'$.
	Therefore, the assignment $Î¦ = [(a, b)] \mapsto ([a], [b])$ is well-defined.
	Injectivity and surjectivity follow immediately.
\end{proof}
The general non-preservation of gradings motivates strengthening the notion of an ideal:
\begin{definition}
	An ideal $I$ of an $R$-graded algebra $A = \bigoplus_{k âˆˆ R} A_k$ is \textdef{homogeneous} if $I = \bigoplus_{k âˆˆ R}I_k$ where $I_k = I \cap A_k$.
\end{definition}
Not all ideals are homogeneous.\sidenote{
	For example, the ideal $I = \gen{\ve_1 + \ve_2 âŠ— \ve_3}$ is distinct from $\bigoplus_{k = 0}^âˆ (I \cap \TA[k]{V}) = \gen{\ve_1, \ve_2 âŠ— \ve_3}$ because the former does not contain $\spanof{\ve_1}$, while the latter does.
}
The additional requirement that an ideal be homogeneous ensures that the associated equivalence relation, as well as respecting the basic algebraic relations of \cref{def:congruence}, also preserves the grading structure.
And so, we have a `graded' analogue to \cref{thm:quotient-algebra-by-congruence}:
\begin{theorem}
	\label{thm:quotient-algebra-by-homogeneous-congruence}
	If $A$ is an $R$-graded algebra and $I$ a homogeneous ideal, then the quotient $\quot A I$ is also $R$-graded.
\end{theorem}
\begin{proof}
	By \cref{lem:quotients-commute-with-direct-sums} and the homogeneity of $I$, we have
	\begin{math}
		\quot A I = \bigoplus_{k âˆˆ R} (\quot{A_k}{I_k})
	.\end{math}
	Elements of $\quot{A_k}{I_k}$ are equivalence classes $[a_k]$ where the representative is of grade $k$.
	Thus, $(\quot{A_p}{I_p}) âŠ› (\quot{A_q}{I_q}) \subseteq \quot{A_{p + q}}{I_{p + q}}$ since $[a_p] âŠ› [a_q] = [a_p âŠ› a_q] = [b]$ for some $b âˆˆ A_{p + q}$.
	Hence, $\quot A I$ is $R$-graded.
\end{proof}



\section{The Wedge Product: Multivectors}

Perhaps the simplest (yet most useful) nontrivial quotient of the tensor algebra is the \emph{exterior algebra}, first popularised in 1844 \cite{grassmann1844} by Hermann Grassmann, who called it the theory of ``extensive magnitudes''.\sidenote{
	\emph{Ausdehnungslehre} in the original German.
}
\begin{definition}
	\label{def:exterior-algebra}
	The \textdef{exterior algebra} over a vector space $V$ is
	\begin{align}
		\EA{V} â‰” \quot{\TA{V}}{ \gen{ğ’–âŠ—ğ’–}}
		\marginnote{
			$\gen{ğ’– âŠ— ğ’–} â‰¡ \gen{ğ’– âŠ— ğ’– | ğ’– âˆˆ V}$ is the ideal defined by $ğ’– âŠ— ğ’– \sim 0$ for any vectors $ğ’– âˆˆ V$.
		}
	.\end{align}
	The product in $\EA{V}$ is called the \textdef{wedge product}, denoted $âˆ§$.
\end{definition}
The wedge product is also called the \emph{exterior}, \emph{alternating} or \emph{antisymmetric} product.
The property suggested by its various names is easily seen by expanding the square of a sum:
\begin{align}
	(ğ’– + ğ’—)âˆ§(ğ’– + ğ’—) = ğ’–âˆ§ğ’– + ğ’–âˆ§ğ’— + ğ’—âˆ§ğ’– + ğ’—âˆ§ğ’—
.\end{align}
Since all terms of the form $ğ’˜âˆ§ğ’˜ = 0$ are definitionally zero, we have
\begin{align}
	ğ’–âˆ§ğ’— = -ğ’—âˆ§ğ’–
\end{align}
for all vectors $ğ’–, ğ’— âˆˆ V$.
By associativity, it follows that $ğ’—_1 âˆ§ ğ’—_2 âˆ§ \cdots âˆ§ ğ’—_k$ vanishes exactly when the $ğ’—_i$ are linearly dependent.\sidenote{
	\begin{proof}
		Blades of the form $a = \etc{ğ’–_\i}âˆ§k$ vanish when two or more vectors are repeated.
		If $\set{ğ’–_i}$ is linearly dependent, then any one $ğ’–_i$ can be written in terms of the others, and thus $a$ can be expanded into a sum of such vanishing terms.
	\end{proof}
}

The ideal $\gen{ğ’– âŠ— ğ’–}$ is homogeneous with respect to the $\ZZ$-grading of the parent tensor algebra,\sidenotemark\ and hence $\EA{V}$ is itself $\ZZ$-graded (by \cref{thm:quotient-algebra-by-homogeneous-congruence}).
In particular, the decomposition into fixed-grade subspaces
\begin{align}
	\EA{V} = \bigoplus_{k=0}^{\dim V} \EA[k]{V}
	\qqtext{where}
	\EA[k]{V} = \spanof{ğ’—_1 âˆ§ ğ’—_2 âˆ§ \cdots âˆ§ ğ’—_k | ğ’—_i âˆˆ V}
,\end{align}
is respected by the wedge product, i.e., $(\EA[p]{V}) âˆ§ (\EA[q]{V}) \subseteq \EA[p + q]{V}$.
\begin{definition}
	An element of $\EA[k]{V}$ is a \textdef{(homogeneous) $k$-vector}.
	An element of $\etc{\EA[k_\i]{V}}âŠ•n âŠ† \EA{V}$ is an \textdef{(inhomogeneous) $\set{\etc{k_\i},n}$-multivector}.
\end{definition}
\sidenotetext{
	This follows because $\gen{ğ’– âŠ— ğ’–}$ is generated by grade $2$ elements $ğ’– âŠ— ğ’– âˆˆ \TA[2]{V}$.
}
All non-zero multivectors are the sum of one or more `irreducible' elements, called \emph{blades}.
\begin{definition}
	A \textdef{$k$-blade} is a term of the form $\etc{ğ’–_\i}âˆ§k$ for $ğ’–_i âˆˆ V$.
\end{definition}
Note that not all $k$-vectors are blades.
For example, the bivector $ğ’–_1 âˆ§ ğ’–_2 + ğ’–_3 âˆ§ ğ’–_4$ is generally not factorizable into a single $2$-blade.

% \Cref{def:homogeneous-and-multivector,def:blade} carry over directly into $\EA{V}$, so elements of $\EA[k]{V}$ are $k$-vectors, and elements of the form $\etc{ğ’–_\i}âˆ§k$ are $k$-blades.


By counting the number of possible linearly independent sets of $k$ vectors in $\dim V$ dimensions, it follows that in base dimension $\dim V = n$,
\begin{align}
	\dim\EA[k]{V} = \binom{n}{k}
,	\qqtext{and hence}
	\dim\EA{V} = 2^{n}
.\end{align}
In particular, note that $\dim \EA[k]{V} = \dim \EA[n - k]{V}$.
Elements of the one-dimensional subspace $\EA[n]{V}$ are called \textdef{pseudoscalars}.\sidenote{
	The prefix `pseudo' means $k \mapsto n - k$.
	Hence, a pseudovector is an $(n - 1)$-vector, etc.
}

Blades have direct geometric interpretations.
The bivector $ğ’– âˆ§ ğ’—$ is interpreted as the directed planar area spanned by the parallelogram with sides $ğ’–$ and $ğ’—$.
(Note that blades have no `shape'; only directed magnitude.)
Similarly, higher-grade elements represent directed \paren{hyper}volume elements spanned by parallelepipeds (see \cref{fig:bivector}).
\begin{marginfigure}
	\includefigure[\columnwidth]{bivector}
	\caption{
		Bivectors and trivectors have orientations induced by the order of the wedge product.
	}
	\label{fig:bivector}
\end{marginfigure}
In fact, any $k$-blade may be viewed as a subspace of $V$ with an oriented scalar magnitude:
\begin{definition}
	The \textdef{span} of a non-zero $k$-blade $b = \etc{ğ’–_\i}âˆ§k$ is the $k$-dimensional subspace
	$\spanof b = \spanof{\etc{ğ’–_\i},k}$.
	Define the span of zero to be the trivial subspace.
\end{definition}
Notably, a blade's span is independent of the particular $âˆ§$-decomposition of the blade into vectors.
(E.g., if $\etc{ğ’–_\i}âˆ§k = \etc{ğ’—_\i}âˆ§k$ are two such decompositions, then $\spanof{ğ’–_i} = \spanof{ğ’—_i}$.)


\subsection{As antisymmetric tensors}
\label{sec:exterior-algebra-as-antisymmetric}

The exterior algebra may equivalently be viewed as the space of antisymmetric tensors equipped with an antisymmetrising product.
% Consider the (anti)\-sym\-metri\-sation map
Consider the map
\begin{align}
	\label{eqn:(anti)symmetriser}
	\op{Sym}^Â±(\etc{ğ’–_\i}âŠ—k) = \frac1{k!} \sum_{Ïƒ âˆˆ S_k} (Â±1)^Ïƒ \etc{ğ’–_{Ïƒ(\i)}}âŠ—k
\end{align}
where $(-1)^Ïƒ$ denotes the sign of the permutation $Ïƒ$ in the symmetric group of $k$ elements, $S_k$.
By requiring linearity, $\op{Sym}^Â± : \TA{V} â†’ \TA{V}$ is defined on all tensors.
A tensor $A$ is called \textdef{symmetric} if $\op{Sym}^+(A) = A$ and \textdef{antisymmetric} if $\op{Sym}^-(A) = A$.

Denote the image $\op{Sym}^-(\TA{V})$ by $S$.
The linear map $\op{Sym}^- : \TA{V} â†’ S$ is \emph{not} an algebra homomorphism with respect to the tensor product on $S$, since, e.g.,
\begin{align}
	\op{Sym}^-(ğ’–âŠ—ğ’—) = \frac12(ğ’–âŠ—ğ’— - ğ’—âŠ—ğ’–) â‰  ğ’– âŠ— ğ’— = \op{Sym}^-(ğ’–)âŠ—\op{Sym}^-(ğ’—)
.\end{align}
However, $\op{Sym}^-$ \emph{is} a homomorphism if we instead equip $S â‰¡ (S, âˆ§)$ with the antisymmetrising product $âˆ§ : S Ã— S â†’ S$ defined by
\begin{align}
	\label{eqn:wedge-as-antisymm}
	A âˆ§ B â‰” \op{Sym}^-(A âŠ— B)
.\end{align}
With this algebra homomorphism, by \cref{thm:first-iso} we have
\begin{align}
	\label{eqn:iso-of-antisym}
	% \quot{\TA{V}}{\ker \op{Sym}^-} \cong \op{Sym}^-(\TA{V})
	S \cong \quot{\TA{V}}{\ker \op{Sym}^-}
.\end{align}
Furthermore, note that the kernel of $\op{Sym}^-$ consists of tensor products of linearly dependent vectors, and sums thereof,\sidenote{
	\begin{proof}
		If $A = \etc{ğ’–_\i}âŠ—k$ where two vectors $ğ’–_i = ğ’–_j$ are equal, then $\op{Sym}^-(A) = 0$ since each term in the sum in \cref{eqn:(anti)symmetriser} is paired with an equal and opposite term with $i â†”ï¸ j$ swapped.
		If $\set{ğ’–_i}$ is linearly dependent, any one vector is a sum of the others, so $A$ is a sum of blades with at least two vectors repeated.
	\end{proof}
}
\begin{align}
	\ker \op{Sym}^- = \spanof{\etc{ğ’–_\i}âŠ—k | k âˆˆ \NN, \text{$\set{ğ’–_i}$ linearly dependent}}
,\end{align}
which is exactly the ideal $\gen{ğ’–âŠ—ğ’–}$.
Therefore, the right-hand side of \cref{eqn:iso-of-antisym} is identically the exterior algebra of \cref{def:exterior-algebra}.
Hence, we have an algebra isomorphism
\begin{math}
	\op{Sym}^-(\TA{V}) \cong \EA{V}
,\end{math}
where the left-hand side is equipped with the product \eqref{eqn:wedge-as-antisymm}.
This gives an alternative construction of the exterior algebra as the subalgebra of antisymmetric tensors.

\subsubsection{Note on normalisation conventions}

The factor of $\frac1{k!}$ present in \cref{eqn:(anti)symmetriser} is not necessary to derive the isomorphism
\begin{math}
	\op{Sym}^-(\TA{V}) \cong \EA{V}
.\end{math}
Indeed, some authors omit the normalisation factor, which has the effect of changing \cref{eqn:wedge-as-antisymm} to\sidenote{
	Written here with $\op{Sym}^-$ \emph{including} the factor $\frac1{k!}$, as in \eqref{eqn:(anti)symmetriser}.
}
\begin{align}
	A âˆ§ B = \frac{(p + q)!}{p!q!}\op{Sym}^-(A âŠ— B)
\end{align}
for $A$ and $B$ of respective grades $p$ and $q$.
These different normalisations of $âˆ§$ lead to distinct identifications of multivectors in $\EA{V}$ with tensors in $S \subset \TA{V}$, as in \cref{tbl:wedge-conventions}.
\begin{table}[h]
	\centering
	\setlength{\tabcolsep}{20pt}
	\renewcommand{\arraystretch}{1.5}
	\begin{tabular}{cc}
		\emph{Kobayashi--Nomizu} \cite{kobayashi1963dg}
	&	\emph{Spivak} \cite{spivak1975dg}
	\\	$A âˆ§ B â‰” \op{Sym}^-(AâŠ—B)$
	&	$A âˆ§ B â‰” \frac{(p + q)!}{p!q!} \op{Sym}^-(AâŠ—B)$
	\\	$ğ’– âˆ§ ğ’— â‰¡ \frac12(ğ’–âŠ—ğ’— - ğ’—âŠ—ğ’–)$
	&	$ğ’– âˆ§ ğ’— â‰¡ ğ’–âŠ—ğ’— - ğ’—âŠ—ğ’–$
	\end{tabular}
	\caption{
		Different embeddings of $\EA{V}$ into $\TA{V}$.
	}
	\label{tbl:wedge-conventions}
\end{table}

Both conventions are present in literature.
We employ the Kobayashi--Nomizu convention for $\EA{V}$ as this is coincides with the wedge product of geometric algebra (see \cref{cha:geometric-algebra}).
However, the Spivak convention is dominant for exterior differential forms in physics.\sidenote{
	E.g., Misner, Thorne, Wheeler \cite{misner1973gravitation}; Flanders \cite{flanders1963differential}; Sharpe, Chern \cite{sharpe2000dg}.	
}



\subsection{Exterior forms}
\label{sec:exterior-forms}

The wedge product is most frequently encountered by physicists as an operation on \emph{exterior (differential) forms}, which are alternating\sidenote{
	An \textdef{alternating} linear map is one which changes sign upon transposition of any pair of arguments.
	% E.g., if $f$ is alternating, then $f(ğ’–, ğ’—, ğ’˜) = -f(ğ’—, ğ’–, ğ’˜)$.
} multilinear maps.
We \emph{could} use the exterior algebra $\EA{V^*}$ over the dual space of linear maps $V â†’ \RR$ as a model for exterior forms, though we will not choose to do this, instead defining them separately.

As to why, consider $\EA{V^*}$ as a model for exterior forms.
Any element $F âˆˆ \EA[k]{V^*}$ has component form $F = F_{\etc{i_\i}{}k} \etc{\ve^{i_\i}}âˆ§k$ for a basis $\set{\ve^i} âŠ‚ V^*$.
By identifying $\EA{V^*} âŠ‚ \TA{(V^*)}$ as antisymmetric tensors, each component acts on $\etc{ğ’–_\i}âŠ—k âˆˆ \TA[k]{V}$ as
\begin{align}
	(\etc{\ve^{i_\i}}âˆ§k)(\etc{ğ’–_\i}âŠ—k)
	&= \frac1{k!} \sum_{Ïƒ âˆˆ S_k} (-1)^Ïƒ\etc{\ve^{i_{Ïƒ(\i)}}(ğ’–_\i)}{}k
\\	&= \frac1{k!}\det[\ve^{i_m}(ğ’–_n)]_{mn}
	\label{eqn:poor-mans-exterior-form}
.\end{align}
However, this differs from the standard definition of exterior forms (as in \cite{spivak1975dg,misner1973gravitation}) in two important ways:
\begin{enumerate}
	\item In \cref{eqn:poor-mans-exterior-form}, the dual vectors $\ve^i âˆˆ V^*$ are permuted while the order of the arguments $ğ’–_i$ are preserved; but for standard exterior forms, the opposite is true.
	This forbids the proper extension of $\EA{V^*}$ to \emph{non-Abelian vector-valued forms}, where the values $\ve^i(ğ’–_j)$ may not commute.
	\item More trivially, we shall insist on the Kobayashi---Nomizu convention of normalisation factor for $\EA{V^*}$; but the Spivak convention for exterior forms is much more common in physics.
\end{enumerate}
For these reasons, we define exterior forms as distinct from $\EA{V^*}$.

\begin{definition}
	\label{def:exterior-form}
	For a vector space $V$ over $\FF$, a \textdef{$k$-form} $Ï† âˆˆ \forms[k](V)$ is an alternating multilinear map $Ï† : \TA[k]{V} â†’ \FF$.

	For another vector space $A$, an \textdef{$A$-valued $k$-form} $Ï† âˆˆ \forms[k](V, A)$ is such a map with codomain $A$ (instead of $\FF$).
\end{definition}
The evaluation of a form is denoted $Ï†(\etc{ğ’–_\i}âŠ—k)$ or $Ï†(\etc{ğ’–_\i},k)$, and the wedge product of a $p$-form $Ï†$ and $q$-form $Ï•$ is defined (in the Spivak convention) as
\begin{align}
	\label{eqn:wedge-of-forms}
	Ï† âˆ§ Ï• = \frac{(p + q)!}{p!q!} (Ï† âŠ— Ï•) \circ \op{Sym}^-
.\end{align}
\Cref{eqn:wedge-of-forms} acts to antisymmetrise \emph{arguments}.
Explicitly, choose a basis $\set{Î¸^Î¼}$ of $\forms(V)$, and compare to \cref{eqn:poor-mans-exterior-form},
\begin{align}
 	(\etc{Î¸^{Î¼_\i}}âˆ§k)(\etc{ğ’–_\i}âŠ—k)
	&= \sum_{Ïƒ âˆˆ S_k} (-1)^Ïƒ \etc{Î¸^{Î¼_\i}(ğ’–_{Ïƒ(\i)})}{}k
% \\	&= \det [Î¸^{Î¼_m}(ğ’–_n)]_{mn}
.\end{align}

% The two algebras $\EA[V]$ and $\forms(V)$ are isomorphic, but differ in that elements of $\forms(V)$ are identified as alternating maps (using the Spivak normalisation convention).
% Consequently, non-homogeneous exterior forms are often disallowed, since they cannot be identified with multilinear maps.
% On the other hand, non-homogeneous elements of $\EA{V}$ find important roles in context of geometric algebra.



\subsubsection{Algebra--valued forms}

If $Ï†, Ï• âˆˆ \forms(V, A)$ are $A$-valued forms, where $A$ is a vector space with a bilinear product $âŠ› : A Ã— A â†’ A$, then their wedge product is
\begin{align}
	(Ï† âˆ§ Ï•)(\etc{ğ’–_\i} âŠ— k) = \sum_{Ïƒ âˆˆ S_k} (-1)^Ïƒ Ï†(\etc{ğ’–_\i} âŠ— p) âŠ› Ï•(\etc{ğ’–_\i} âŠ— q)
.\end{align}
Note that $âŠ›$ replaces scalar multiplication as the natural product between the forms' valuations.
Thus we may have matrix--valued forms where $âŠ›$ is matrix multiplication, or vector--valued forms with the tensor product --- but $âŠ›$ need not be commutative nor associative.

In particular, we may have Lie algebra--valued forms, taking the Lie bracket $[\phantom{ğ’–}, \phantom{ğ’–}]$ to be the bilinear product. 
For example, if $Ï†, Ï• âˆˆ \forms[1](V, \liealg g)$ for a Lie algebra $\liealg g$, then
\begin{align}
	(Ï† âˆ§ Ï•)(ğ’–, ğ’—) = [Ï†(ğ’–), Ï•(ğ’—)] - [Ï†(ğ’—), Ï•(ğ’–)]
.\end{align}
Note that `wedge-squares' $Ï† âˆ§ Ï†$ do not necessarily vanish for non-Abelian $1$-forms.
For the example above, $(Ï† âˆ§ Ï†)(ğ’–, ğ’—) = 2[Ï†(ğ’–), Ï†(ğ’—)]$.




\section{The Metric: Length and Angle}

The tensor and exterior algebras considered so far are built from a vector space $V$ alone.
Notions of length and angle are central to geometry, but are not intrinsic to a vector space --- this additional structure may be provided by a \emph{metric}.
\begin{definition}
	A \textdef{metric}\,\sidenote{a.k.a. an \emph{inner product}, or \emph{symmetric bilinear form}} is a function $Î· : V Ã— V \to \FF$, often written $\ip{ğ’–, ğ’—} â‰¡ Î·(ğ’–, ğ’—)$, which satisfies
	\begin{itemize}
		\item symmetry, $\ip{ğ’–, ğ’—} = \ip{ğ’—, ğ’–}$; and
		\item linearity, $\ip{Î±ğ’– + Î²ğ’—, ğ’˜} = Î±\ip{ğ’–, ğ’˜} + Î²\ip{ğ’—, ğ’˜}$ for $Î±, Î² \in \FF$.
	\end{itemize}
\end{definition}

By symmetry $Î·$ is bilinear.
Note we do not require $\ip{ğ’–, ğ’—}$ to be non-negative, or for $Î·$ to satisfy the triangle inequality.\sidenote{
	$\|ğ’– + ğ’—\| â‰¤ \|ğ’–\| + \|ğ’—\|$ where $\|ğ’–\|^2 = \ip{ğ’–,ğ’–}$
}

A metric is \textdef{non-degenerate} if
\begin{math}
	\ip{ğ’–, ğ’—} = 0
\end{math}
for all $ğ’–$ implies that $ğ’—$ is zero.
With respect to a basis $\set{\ve_i}$ of $V$, the metric components
\begin{math}
	Î·_{ij} = \ip{\ve_i, \ve_j}
\end{math}
are defined.
Non-degeneracy means that $\det Î· â‰  0$ when viewing $Î· = [Î·_{ij}]$ as a matrix, and in this case the matrix inverse $Î·^{ij}$ is also defined and satisfies $Î·^{ik}Î·_{kj} = Î´^i_j$.
Throughout, we will not have need to consider degenerate metrics,\sidenote{
	Degenerate signatures do find use in computer graphics, especially via \emph{projective geometric algebra} \cite{hestenes1991pga,vince2008ga-graphics}.
} so we assume non-degeneracy.

A vector space $V$ together with a metric $Î·$ is called an \textdef{inner product space} $(V, Î·)$.
Alternatively, instead of a metric, an inner product space may be constructed with a quadratic form:
\begin{definition}
	A \textdef{quadratic form} is a function $q : V \to \FF$ satisfying
	\begin{itemize}
		\item $q(Î»ğ’—) = Î»^2q(ğ’—)$ for all $Î» \in \FF$; and
		\item the requirement that the \textdef{polarization of $q$},
		\begin{align}
			(ğ’–, ğ’—) \mapsto q(ğ’– + ğ’—) - q(ğ’–) - q(ğ’—)
		,\end{align}
		is bilinear.
	\end{itemize}
\end{definition}
To any quadratic form $q$ there is a unique associated bilinear form, which is \emph{compatible} in the sense that $q(ğ’–) = \ip{ğ’–,ğ’–}$.
It is recovered\sidenote{
	Except, of course, if the characteristic of $\FF$ is two.
	We only consider fields of characteristic zero.
} by the \emph{polarization identity}
\begin{align}
	\ip{ğ’–, ğ’—} = \frac12\qty\big(q(ğ’– + ğ’—) - q(ğ’–) - q(ğ’—))
.\end{align}
The prescription of either $Î·$ or $q$ is therefore equivalent --- but the notion of a metric is more common in physics, whereas the mathematical viewpoint often starts with a quadratic form.


\subsubsection{Covectors and dual bases}

The dual space $V^* â‰” \set{f : V â†’ \FF | \text{$f$ linear}}$ of a vector space consists of \textdef{dual vectors} or \textdef{covectors}, which are linear maps from $V$ into its underlying field.
Summation convention dictates that components of vectors be written superscript, $ğ’– = u^i\ve_i âˆˆ V$, and covectors subscript, $Ï† = Ï†_i\ve^i âˆˆ V^*$, for bases $\set{\ve_i} \subset V$ and $\set{\ve^i} \subset V^*$.

A metric $Î·$ on $V$ defines an isomorphism between $V$ and its dual space.
Collectively known as the \textdef{musical isomorphisms}, the maps $\flat : V â†’ V^*$ and its inverse $\sharp : V^* â†’ V$ are defined by
\begin{align}
	ğ’–^\flat(ğ’—) = \ip{ğ’–, ğ’—}
	\qqtext{and}
	\ip{Ï†^\sharp, ğ’–} = Ï†(ğ’–)
\end{align}
for $ğ’–,ğ’— âˆˆ V$ and $Ï† âˆˆ V^*$.
The names become justified when working with a basis: the relations
\begin{align}
	(ğ’–^\flat)_i = Î·_{ij}ğ’–^j
	\qqtext{and}
	(Ï†^\sharp)^i = Î·^{ij}Ï†_j
\end{align}
show that $\flat$ \emph{lowers} indices, while $\sharp$ \emph{raises} them.

Given a metric, a choice of basis $\set{\ve_i} âŠ‚ V$ also defines a \textdef{dual basis $\set{\ve^i} \subset V^*$ of $V$} via
\begin{math}
	\ve^i â‰” Î·^{ij}\ve_j^\flat
.\end{math}
Note that basis vectors and covectors defined in this way do not exist in the same vector space, but are related by their evaluation on one another by $\ve^i(\ve_j) = Î´^i_j$.
In some contexts, we will define a dual basis $\set{\ve^i}$ in $V$ (not in $V^*$), a.k.a.\ a \textdef{reciprocal basis}, and by this we mean
\begin{math}
	\ve^i â‰” Î·^{ij}\ve_j
.\end{math}
Then, dual and non-dual basis vectors are related via $\ip{\ve^i, \ve_j} = Î´^i_j$.

We use both senses of the term ``dual basis''.
In particular, $V^*$ is never needed in the geometric algebra; its role is filled by reciprocal bases.
Often, the distinction can be safely ignored (since, after all, $V \cong V^*$).

%  or $\ve^i = Î·^{ij}\ve_j$.

\subsection{Metrical exterior algebra}
\label{sec:metrical-exterior-alg}

In an exterior algebra $\EA{V}$ with a metric defined on $V$, there is an induced metric on $k$-vectors defined by
\begin{align}
	\ip{\etc{ğ’–_\i}âˆ§k, \etc{ğ’—_\i}âˆ§k}
	&= \sum_{Ïƒ âˆˆ S_k} (-1)^Ïƒ \etc{\ip{ğ’–_\i, ğ’—_{Ïƒ(\i)}}}{}k
\\	&= \det [\ip{ğ’–_m, ğ’–_n}]_{mn}
	\label{eqn:induced-metric}
.\end{align}
In particular, a metric on $\EA{V}$ defines a magnitude for pseudoscalars.
\begin{definition}
	\marginnote{
		Note that $\vol$ is \emph{not} the identity matrix, $\mathbb{1}$.
		It is more analogous to the complex unit $i$, with square $\vol^2 = Â±1$ depending on dimension and metric.
		Similar notation is used in \cite{doran2003ga,hestenes2003sta,hestenes1986ga-unified-language}.
	}
	Let $V$ be an $n$-dimensional vector space with a metric.
	There are two volume elements $\vol âˆˆ \EA[n]{V}$ of the metrical exterior algebra $\EA{V}$ is a pseudoscalar satisfying $\ip{\vol, \vol} = 1$, each differing by sign.

	A choice of volume element defines an \textdef{orientation}.
\end{definition}
Given an ordered orthonormal basis $\set{\ve_i}$ with $\ip{\ve_i, \ve_i} = Â±1$, the basis is called right-handed if $\etc{\ve_\i}âˆ§n = \vol$ is the chosen volume element, and left-handed otherwise.


\subsubsection{Hodge--dual multivectors}

\marginnote{
	\emph{Hodge duality:} \cite{flanders1963differential,misner1973gravitation}, \cite[Â§16]{lee2012diffgeo}.

}[-4.1ex]

A useful duality operation can be defined in an exterior algebra $\EA{V}$ with a metric and orientation, which relates the $k$- and $(n - k)$-grade subspaces.
\begin{definition}
	\label{def:hodge-dual}
	Let $\EA{V}$ be a metrical exterior algebra with base dimension $n$ and volume element $\vol$.
	The \textdef{Hodge dual} $\star$ is the unique linear operator satisfying
	\begin{align}
		\label{eqn:hodge-dual}
		A âˆ§ \star B = \ip{A, B}\vol
	\end{align}
	for any $k$-vectors $A, B âˆˆ \EA[k]{V}$.
\end{definition}

The Hodge dual $\star : \EA[k]{V} â†’ \EA[n - k]{V}$ defines an isomorphism between pairs of fixed-grade subspaces of the same dimension; in particular, scalars with pseudoscalars via $\star 1 = \vol$.

\begin{lemma}
	The hodge dual of a $p$-vector $A = A^{i_1â‹¯i_p} \etc{\ve_{i_\i}}âˆ§p$ has components
	\begin{align}
		(\star A)^{j_1â‹¯j_q} = \frac1{p!} A_{i_1â‹¯i_p} Îµ^{i_1â‹¯i_p j_1â‹¯j_q}
		\marginnote{
			The \textdef{Levi-Civita symbol} $Îµ_{i_1â‹¯i_n}$ is the unique totally\hyp antisymmetric tensor with $Îµ_{1â‹¯n} = 1$.
		}
	\end{align}
	where $A_{i_1â‹¯i_p} = \etc{Î·_{i_\i j_\i}}{}p \, A^{j_1â‹¯k_p}$ and $Îµ^{i_1â‹¯i_n} = \etc{Î·^{i_\i j_\i}}{}n \, Îµ_{j_1â‹¯j_n}$.
\end{lemma}
\begin{proof}
	We will show this by writing $A âˆ§ \star B = \ip{A, B}\vol$ in component form and rearranging for $\star B$.
	The left-hand side is
	\begin{align}
		\label{eqn:hodge-dual-lem.1}
		A âˆ§ \star B
		&= A^{i_1â‹¯i_p} \, (\star B)^{j_1â‹¯j_q} \, \etc{\ve_{i_\i}}âˆ§p âˆ§ \etc{\ve_{j_\i}}âˆ§q
	\\	&= A^{i_1â‹¯i_p} \, (\star B)^{j_1â‹¯j_q} \, Îµ_{i_1â‹¯i_p j_1â‹¯j_q} \vol
	,\end{align}
	while the right-hand side is
	\begin{math}
		\ip{A, B} \vol = A^{i_1â‹¯i_p}B_{i_1â‹¯i_p} \vol
	.\end{math}
	Equating coefficients yields
	\begin{align}
		(\star B)^{j_1â‹¯j_q} Îµ_{i_1â‹¯i_p j_1â‹¯j_q} = B_{i_1â‹¯i_p}
	.\end{align}
	Finally, contracting with $Îµ^{i_1â‹¯i_p k_1â‹¯k_q}$ gives
	\begin{align}
		(\star B)^{k_1â‹¯k_q} = \frac1{p!} B_{i_1â‹¯i_p} Îµ^{i_1â‹¯i_p k_1â‹¯k_q}
	\end{align}
	since $Îµ_{i_1â‹¯i_p j_1â‹¯j_q} Îµ^{i_1â‹¯i_p k_1â‹¯k_q} = (-1)^Ïƒ p!$ where $Ïƒ$ is the permutation sending $j_i \mapsto k_i$.
	The factor of $(-1)^Ïƒ$ is absorbed since $(\star B)^{j_1â‹¯j_q} = (-1)^Ïƒ (\star B)^{k_1â‹¯k_q}$.
	Replacing $B â†¦ A$ is the result as written.
\end{proof}

\begin{lemma}
	\label{lem:inv-hodge}
	The inverse Hodge dual of a $k$-vector $A$ is
	\begin{align}
		\star^{-1} A = (-1)^s (-1)^{k(n - k)} \star A
	\end{align}
	where $s = \tr Î·$ is the signature of the metric.
\end{lemma}
\begin{proof}
	It is much easier to work in the (yet to be defined) geometric algebra, referring forward to \cref{sec:ga-hodge-dual} for the relation $\star A = \rev{A}\vol$.
	\marginnote{
		$â€ $ is reversion; \cref{eqn:rev-notation}.
		$\revsign{k} = Â±1$ is the reversion sign; \cref{eqn:reversion-sign}.
	}
	Then, $\star^{-1} A = \rev{(A\vol^{-1})}$ since $\star^{-1}\star A = \rev{(\rev{A}\vol \vol^{-1})} = A$ and $\star \star^{-1} A = \rev{\rev{(A \vol^{-1})}{}} \vol = A$.
	Translating this back into $\EA{V}$,
	\begin{align}
		\star^{-1} A
		&= \rev{(A\vol^{-1})}
	\\	&= \revsign{n - k} \, A \vol^{-1}
	&	&\text{since $A\vol^{-1}$ is of grade $n - k$;}
	\\	&= \revsign{k}\revsign{n - k} \, \rev{A} \vol^{-1}
	&	&\text{since $A$ is of grade $k$;}
	\\	&= (-1)^s \revsign{n} \revsign{k}\revsign{n - k} \, \rev{A} \vol
	&	&\text{since $\vol^{-1} = (-1)^s \rev{\vol} = (-1)^s \revsign{n} \vol$;}
	\\	&= (-1)^s (-1)^{k(n-k)} \star A
	&	&\text{by simplifying with \cref{eqn:reversion-sign}}
	.\end{align}
\end{proof}