\chapter{Calculus in Flat Geometries}

So far, we have been concerned with special relativity at a single point in spacetime.
We move now toward the description of \emph{fields} --- quantities extending across regions of spacetime.
The first step in this direction is the calculus of \emph{flat spacetime}.
In a flat geometry, we may assume that
\begin{itemize}
	\item points in spacetime are elements of a vector space, with differences of points being physically meaningful; and that
	\item fields are parametric functions of a single vector argument representing a location in spacetime.
\end{itemize}
We reserve the word \textdef{field} to mean a map with a fixed vector space codomain.
For instance, the electromagnetic bivector field in flat space $F : \RR^4 â†’ \EA[2]{\RR^4}$ is a function between fixed vector spaces.
In particular, the value of a vector field $F : V â†’ A$ at different points in spacetime can be added; $F(x) + F(y) âˆˆ A$.

These assumptions are acceptable in special relativity, but in arbitrary regions of spacetime and in the presence of gravity, curvature prevents spacetime from admitting a meaningful vector space structure, and it becomes unphysical to compare field values at different points.
(Consideration of curvature leads to differential geometry and comprises \cref{part:2}.)


\section{Differentiation}


The directional derivative of a vector field $F : V â†’ A$ in the direction $ð’– âˆˆ V$ is
\begin{align}
	% âˆ‚_ð’– F(x) = \lim_{Îµ â†’ 0}\frac{F(x + Îµð’–) - F(x)}{Îµ}
	âˆ‚_ð’– F(x) = \dv{Îµ} \eval{F(x + Îµð’–)}_{Îµ = 0}
	= \lim_{Îµ â†’ 0}\frac{F(x + Îµð’–) - F(x)}{Îµ}
\end{align}
where the point $x âˆˆ V$ is also a vector.
The directional derivative is linear in $ð’–$, since by a change of variables,
\begin{math}
	âˆ‚_{u^a\ve_a}
	= \sum_a \dv{Îµ} \eval{F(x + Îµu^a\ve_a)}_{Îµ = 0}
	= \sum_a u^a \dv{Îµ'} \eval{F(x + Îµ'\ve_a)}_{Îµ' = 0}
	= u^a âˆ‚_{\ve_a}
.\end{math}


Suppose $F : V â†’ A$ is some algebra--valued field.
It is useful to define a kind of ``total'' derivative $\DD F$ which does not depend on a direction of differentiation $ð’–$, but instead encompasses, in a sense, all derivatives in a single object $\DD F : V â†’ A$.
The motivation for this is that it encompasses as special cases the soon-to-be-defined exterior derivative (of exterior algebra) and vector derivative (of geometric algebra).
This derivative will be defined when there is a canonical inclusion $Î¹ : V^* â†’ A$ of dual vectors into the algebra $A$, which is automatic if $A$ is a quotient of $\TA{(V^*)}$.

\begin{definition}
	\label{def:algder}
	Let $F : V â†’ A$ be a field with values in an algebra $A$ with product $âŠ›$, equipped with an inclusion $Î¹ : V^* â†’ A$.
	The \textdef{algebraic derivative} of $F$ is
	\begin{align}
		\label{eqn:algder}
		\DD F â‰” Î¹(\ve^a) âŠ› âˆ‚_{\ve_a} F
	\end{align}
	(summation on $a$) where $\set{\ve_a} âŠ‚ V$ and $\set{\ve^a} âŠ‚ V^*$ are dual bases.
\end{definition}

To understand this definition, consider the simple case of the free tensor algebra $F : V â†’ \TA{(V^*)}$.
We leave the canonical inclusion $Î¹ : V^* â†’ \TA{(V^*)}$ implicit.
Given a basis $\set{\ve^a} âŠ‚ V^*$, the algebraic derivative is
\begin{math}
	\DD F = \ve^a âŠ— âˆ‚_a F
,\end{math}
which simply encodes the partial derivatives of a $k$-vector $F$ in a $(k + 1)$-grade object.
In component language,
\begin{math}
	(\DD F)_{a\etc{a_\i}{}k} = âˆ‚_aF_{\etc{a_\i}{}k}
.\end{math}

\subsection{The Exterior Derivative}

Consider a vector field $F : V â†’ \EA{V^*}$ with values in the (dual) exterior algebra.
In this case \cref{eqn:algder} is the \textdef{exterior derivative}
\begin{align}
	\dd F = \dx^a âˆ§ \pdv{F}{x^a}
\end{align}
where $\set{\dx^a} âŠ‚ V^*$ also form a dual basis of $\EA{V^*}$.
If $F : V â†’ \EA[k]{V^*}$ is a $k$-vector field, then
\begin{math}
	\dd F = âˆ‚_a F_{\etc{a_\i}{}k} \dx^a âˆ§ \etc{\dx^{a_\i}}âˆ§k
\end{math}
is a $(k + 1)$-vector.

Using the equivalence of $\EA{V^*}$ with the subspace of antisymmetric tensors (see \cref{sec:exterior-algebra-as-antisymmetric}), the exterior derivative is seen to be the totally anti-symmetrised partial derivative.
In components,
\begin{math}
	(\dd F)_{\etc{a_\i}{}k} = âˆ‚_{[a_1}F_{\etc[2]{a_\i}{}k]}
.\end{math}

The treatment of exterior forms is identical.
An exterior form field $Ï† : V â†’ \forms[k](V, U)$ is called a $U$-valued \textdef{exterior differential $k$-form}, with exterior derivative defined via its action on vectors
\begin{align}
	(\dd Ï†)(ð’–, \etc{ð’–_\i},{k})
	&= (\dx^a âˆ§ âˆ‚_a Ï†)(ð’–, \etc{ð’–_\i},k)
% \\	&= \sum_{Ïƒ âˆˆ S_{k + 1}} (-1)^Ïƒ âˆ‚_{ð’–_{Ïƒ(0)}} Ï†(\etc{ð’–_{Ïƒ(\i)}}{}k)
\\	&= \sum_{i = 0}^k (-1)^i âˆ‚_{ð’–_{i}} Ï†(ð’–_0, ..., \widehat{ð’–_i}, ..., ð’–_k)
\end{align}
in the Spivak convention (see \cref{sec:exterior-forms}).
Note that the partial derivative acts on the position dependence of $Ï†$ only --- the vectors $ð’–_i âˆˆ V$ are fixed input vectors.
This changes when generalising from vector fields of alternating maps to forms defined on a \emph{manifold}, where correction terms are needed to account for partial derivatives of input vectors (discussed in \cref{part:2}).


\subsection{The Vector Derivative}

The algebraic derivative in the tensor and exterior algebras are somewhat uninteresting, because they are easily expressible in component form (e.g., $âˆ‚_aF_{\etc{a_\i}{}k}$ or $âˆ‚_{[a}F_{\etc{a_\i}{}k]}$).
This is not possible in the geometric algebra, however, because $\GA(V, Î·)$ is not $\ZZ$-graded, and we would face the problem of notating inhomogeneous objects with a variable number of indices.
The algebraic derivative is, however, still geometrically significant and useful in this case.

In $\GA(V, Î·)$, the algebraic derivative is called the \textdef{vector derivative}, which we denote $\vd$.
Explicitly, if $F : V â†’ \GA(V, Î·)$ is a multivector field, then in \cref{eqn:algder} we take $âŠ›$ to be with the geometric product and take the inclusion to be\sidenote{
	We could just as well consider fields $V â†’ \GA(V^*, Î·)$, avoiding the need for the isomorphism $\sharp : V^* â†’ V$.
	But the metric is already defined, so we prefer multivectors $\GA(V, Î·)$ to `dual-multivectors'.
}
\begin{math}
	V^* âˆ‹ ð’– â†¦ Î¹(ð’–^\sharp) âˆˆ \GA(V, Î·)
.\end{math}
Here, we use the metric to relate $V^* â†’ V$ and the canonical inclusion $Î¹ : V â‰¡ \GA[1](V, Î·) â†’ \GA(V, Î·)$.
The vector derivative is then
\begin{align}
	\vd F = \ve^a \, âˆ‚_{\ve_a} F
\end{align}
(summation on $a$) where $\set{\ve_a} âŠ‚ V$ and $\set{\ve^a} âŠ‚ V$ are dual bases, and juxtaposition denotes the geometric product.
If $F$ is a homogeneous $k$-vector, then we may write its components as
\begin{math}
	F = F_{\etc{a_\i}{}k} \etc{\ve^{a_\i}}âˆ§k
\end{math}
and hence
\begin{align}
	\vd F = âˆ‚_{\ve_a}F_{\etc{a_\i}{}k} \, \ve^a(\etc{\ve^{a_\i}}âˆ§k)
.\end{align}
Note that these terms are not $(k + 1)$-blades, but geometric products of vectors $\ve^a$ with $k$-blades --- in general, $(k Â± 1)$-multivectors.

We may regard the vector derivative itself as an operator-valued vector,
\begin{align}
	\vd = \ve^a âˆ‚_a
,\end{align}
reflecting the fact that $\vd$ behaves algebraically like a vector.
For instance, the derivative of a vector $ð’–$ has scalar and bivector parts,
\begin{math}
	\vd ð’– = \vd \fatdot ð’– + \vd âˆ§ ð’–
,\end{math}
just like the geometric product of two vectors, $ð’–ð’— = ð’– \fatdot ð’— + ð’– âˆ§ ð’—$.
For a general multivector $F$, then, we have
\begin{align}
	\vd F = \vd \lcontr F + \vd âˆ§ F
.\end{align}


\subsection{Case Study: Maxwell's Equations}


Expressed in the standard vector calculus of $\RR^3$, Maxwell's equations for the electric $\vb E$ and magnetic $\vb B$ fields in the presence of a source are
\begin{align}
	âˆ‡ \cdot \vb E &= \frac{Ï}{Îµ_0} &&\text{(GauÃŸ' law)}
\\	âˆ‡ \cdot \vb B &= 0 &&\text{(Absence of magnetic monopoles)}
\\[1ex]	âˆ‡ Ã— \vb E &= -âˆ‚_t \vb B &&\text{(Faraday's law)}
\\[1ex]	âˆ‡ Ã— \vb B &= Î¼_0(\vb J + Îµ_0âˆ‚_t \vb E) &&\text{(AmpÃ¨re's law)}
\end{align}
where $Ï$ is the scalar charge density and $\vb J$ the current density.
The constants $Îµ_0$ and $Î¼_0$ are the vacuum permittivity and permeability, respectively, related to the speed of light $c$ by $Îµ_0Î¼_0c^2 = 1$.



\begin{margintable}
	\footnotesize
	\begin{tabular}{cl}
		\\
		\multicolumn{2}{c}{\emph{Non-relativistic}} \\
		quantity & dimension \\
		$\vb E$ & $MQ^{-1}LT^{-2}$ \\
		$\vb B$ & $MQ^{-1}T^{-1}$ \\
		$Ï$ & $QL^{-3}$ \\
		$\vb J$ & $QT^{-1}L^{-2}$ \\
		$Î¼_0$ & $MQ^{-2}L$ \\
		$Îµ_0$ & $M^{-1}Q^2L^{-3}T^2$ \\
		$âˆ‡$, $âˆ‚_t$ & $L^{-1}$, $T^{-1}$ \\
		$c$ & $LT^{-1}$ \\
		\\
		\multicolumn{2}{c}{\emph{Relativistic}} \\
		quantity & dimension \\
		$F$ & $MQ^{-1}S^{-1}$ \\
		$J$ & $QS^{-3}$ \\
		$Î¼_0$, $Îµ_0^{-1}$ & $MQ^{-2}S$ \\
		$âˆ‚$ & $S^{-1}$ \\
		$c$ & $1$ \\
	\end{tabular}
	\caption{
		Dimensions of physical quantities in Maxwell's equations.
		$M$ is mass, $Q$ is electric charge, $T$ is duration and $L$ is length.
		In the relativistic formulation, $T$ and $L$ are unified and replaced by \emph{spacetime interval} $S$.
	}
\end{margintable}

These can be expressed relativistically as eight scalar equations,
\begin{align}
	\label{eqn:maxwells-tensor-form}
	âˆ‚_Î¼F^{Î¼Î½} &= Î¼_0J^Î½
,&	âˆ‚_Î¼G^{Î¼Î½} &= 0
\end{align}
where $F^{Î¼Î½} = -F^{Î½Î¼}$ is the Faraday tensor and $G^{Î¼Î½}$ its Hodge dual, both encoding the electric and magnetic fields via
\begin{align}
	\label{eqn:components-of-electromagnetic-tensor}
	F^{i0} &= \frac{E^i}{c}
,&	F^{ij} &= -Îµ^{ijk}B_k
,&	G^{Î¼Î½} &= \frac12 Îµ^{Î¼Î½}{}_{ÏÏƒ} F^{ÏÏƒ}
% ,&	G^{Î¼Î½} &= \frac12 Î·^{Î¼Ï}Î·^{Î½Ïƒ}Îµ_{ÏÏƒÎ»Ï…} F^{Î»Ï…}
,\end{align}
and where $J^Î¼$ encodes both the static charge density $J^0 = cÏ$ and current density $J^i = \vb J$.
The left of eqs.~\eqref{eqn:maxwells-tensor-form} is the \emph{source equation}, while the right is the \emph{second Bianchi identity}.



\begin{proof}
	We show how the relativistic equations \eqref{eqn:maxwells-tensor-form} reduce to the non-relativistic vector calculus equivalents.
	The $0$-component of the source equation is
	$âˆ‚_Î¼ F^{Î¼0} = âˆ‚_iE^i/c = Î¼_0J^0 = Î¼_0cÏ$ implying $âˆ‡ Â· \vb E = Î¼_0c^2Ï = Ï/Îµ_0$ (GauÃŸ' law).
	The $i$-components are
	\begin{align}
		âˆ‚_0F^{0i} + âˆ‚_jF^{ji} &= \frac1câˆ‚_t\qty(-\frac{E^i}{c}) - âˆ‚_jÎµ^{jik}B_k = Î¼_0 J^i
\\		\qqtext{or} âˆ‚_jÎµ^{ijk}B_k &= Î¼_0 J^i + Î¼_0Îµ_0âˆ‚_tE^i
	,\end{align}
	which is equivalent to AmpÃ¨re's law.
	The $0$-component of the Bianchi identity $âˆ‚_Î¼G^{Î¼0} = 0$ is
	\begin{align}
		% \frac12 Îµ^{i0}{}_{Î¼Î½}âˆ‚_iF^{Î¼Î½}
		\frac12 Îµ^i{}_{jk}âˆ‚_iF^{jk}
		= -\frac12 Îµ^i{}_{jk}Îµ^{jkl}âˆ‚_iB_l
		= -âˆ‚_iB^i = 0
	,\end{align}
	which using the identity $Îµ_{ijk}Îµ^{jkl} = 2Î´^l_i$ is $âˆ‡ Â· \vb B = 0$.
	Finally, the $i$-component gives
	\begin{align}
		0 = âˆ‚_Î¼G^{Î¼i} &= \frac12Îµ^{Î¼i}{}_{ÏÏƒ}âˆ‚_Î¼F^{ÏÏƒ}
		= \frac12Îµ^{0i}{}_{jk}âˆ‚_0F^{jk} + Îµ^{ji}{}_{k0}âˆ‚_jF^{k0}
	\\	&= -\frac14Îµ^i{}_{jk}Îµ^{jkl}âˆ‚_0B_l - \frac1{2c} Îµ^{ijk}âˆ‚_jE_k
		= -\frac1{2c}\qty(âˆ‚_tB^i  + Îµ^{ijk}âˆ‚_jE_k)
	\end{align}
	yielding Faraday's law $âˆ‡ Ã— \vb E = -âˆ‚_t \vb B$.
\end{proof}



\subsection{With exterior calculus}

It is easy to translate from the language of exterior calculus to the tensor calculus, and hence vice versa, by identifying the former as the subalgebra of totally antisymmetric tensors, as in \cref{sec:exterior-algebra-as-antisymmetric}.
We will employ the Spivak convention, which in particular makes the identification
\begin{align}
	\ve^Î¼ âˆ§ \ve^Î½ â‰¡ \ve^Î¼ âŠ— \ve^Î½ - \ve^Î½ âŠ— \ve^Î¼
\end{align}
where $\ve^Î¼$ are spacetime basis vectors.







\section{Integration}


\subsection{Stokes' Theorem for Exterior Calculus}

\begin{theorem}[Stokes' theorem in $\RR^n$]
	\label{thm:flat-stokes}
	If $R âŠ† \RR^n$ is a compact $k$-dimensional hypersurface with boundary $âˆ‚R$, then a smooth differential form $Ï‰ âˆˆ \forms[k - 1](R)$ satisfies
	\begin{align}
		\label{eqn:stokes}
		\int_R \dd Ï‰ = \int_{âˆ‚R} Ï‰
	.\end{align}
\end{theorem}
\begin{proof}
	Since $R$ is a $k$-dimensional region with boundary, every point $x âˆˆ R$ has a neighbourhood diffeomorphic to a neighbourhood of the origin in either $\RR^k$ or $H^k â‰” [0, âˆž) âŠ• \RR^{k - 1}$, depending on whether $x$ is an interior point or a boundary point, respectively.

	\begin{marginfigure}
		\centering
		\includefigure[\columnwidth]{stokes-theorem}
		\caption{
			Neighbourhoods in $R$ are diffeomorphic either to interior balls or boundary half-balls.
		}
		\label{fig:stokes-theorem}
	\end{marginfigure}

	Let $\set{U_i}$ be a cover of $R$ consisting of such neighbourhoods.
	Since $R$ is compact, we may assume $\bigcup_{i=1}^N \set{U_i} = R$ to be a finite covering.
	Thus, we have finitely maps $h_i : U_i â†’ X$ where $X$ is either $\RR^k$ or the half-space $H^k$, where $U_i \cong h_i(U_i)$ are diffeomorphic (see \cref{fig:stokes-theorem}).

	Finally, let $\set{Ï•_i : R â†’ [0, 1]}$ be a partition of unity subordinate to $\set{U_i}$, so that $\set{x âˆˆ R | Ï•_i(x) > 0} âŠ† U_i$ and $Ï‰ = \sum_{i=1}^N Ï•_iÏ‰$.
	We need only prove the equality \eqref{eqn:stokes} for each $Ï‰_i â‰” Ï•_iÏ‰$, and the full result follows be linearity.
	
	The form $h_i^*Ï‰_i âˆˆ \forms[k - 1](X)$ can be written with respect to canonical coordinates of $X$ as
	\begin{align}
		h_i^*Ï‰_i = \sum_{j=1}^k f_j (-1)^{j - 1} \dd x^{1\cdots\hat{j}\cdots k}
	\end{align}
	using the multi-index notation $\dx^{\etc{i_\i}{}k} â‰¡ \etc{\dx^{i_\i}}âˆ§k$, where the hat denotes an omitted term.
	The factor of $(-1)^{j - 1}$ gives the $(k - 1)$-form the boundary orientation induced by the volume form $\dx^{\etc\i{}k}$ for convenience.
	Since pullbacks commute with $\dd$,
	\begin{align}
		h^*\ddÏ‰_i = \dd(h_i^*Ï‰_i) = \sum_{j=1}^k \pdv{f_j}{x^j} \dd x^{1\cdots n}
	.\end{align}
	There are then two cases to consider.
	\begin{itemize}
		\item \emph{Interior case.}
		If $h_i : U_i â†’ \RR^k$, then the right-hand side of \cref{eqn:stokes} vanishes because $Ï‰_i$ is zero outside the neighbourhood $U_i âŠ‚ R$ which nowhere meets the boundary $âˆ‚R$.
		\begin{align}
			\int_{âˆ‚R} Ï‰_i = \int_{âˆ‚U_i} Ï‰_i = \int_âˆ… Ï‰_i = 0
		\end{align}
		The left-hand side evaluates to
		\begin{align}
			\int_R \dd Ï‰_i
			&= \int_X \dd (h_i^*Ï‰_i)
			= \int_{\RR^k} \sum_{j=1}^k \pdv{f_j}{x^j} \dd x^{1\cdots n}
		\\	&= \underbrace{\etc{\int_{-âˆž}^{+âˆž}}{}{}}_k \sum_{j=1}^k \pdv{f_j}{x^j} \etc{dx^\i}{}{k}
		\\	&= \underbrace{\etc{\int_{-âˆž}^{+âˆž}}{}{}}_{k - 1} \sum_{j=1}^k \eval{f_j}_{x^j=-âˆž}^{+âˆž} (-1)^{j-1} dx^1\cdots\widehat{dx^j}\cdots dx^k
			= 0
		,\end{align}
		which vanishes because $h_i^*Ï‰_i$, and hence the $f_j$, vanish outside the neighbourhood $h_i(U_i) âŠ‚ \RR^k$.

	\item \emph{Boundary case.}
	If $h_i : U_i â†’ H^k$, then the boundary $âˆ‚U_i âŠ‚ âˆ‚R$ is mapped onto the hyperplane $âˆ‚H^k = \set{(0, \etc[2]{x^\i},k) | x^j âˆˆ \RR}$.
	Thus, $dx^1 = 0$ on this boundary, and the right-hand side of \cref{eqn:stokes} becomes
	\begin{align}
		\int_{âˆ‚R}Ï‰_i
		&= \int_{âˆ‚U_i} h_i^*Ï‰_i
		= -\int_{\RR^{k - 1}} f_1 \etc[2]{dx^\i}{}k
	\\	&= -\underbrace{\etc{\int_{-âˆž}^{+âˆž}}{}{}}_{k - 1} f_1(0, \etc[2]{x^\i},k) \etc[2]{dx^\i}{}k
	.\end{align}
	The factor of $-1$ comes from the induced orientation of the boundary $âˆ‚H^k$, which is outward-facing, so in the \emph{negative} $x^1$ direction.
	For the left-hand side of \cref{eqn:stokes},
	\begin{align}
		\int_R \dd Ï‰_i
		&= \int_{H^k} h_i^*\ddÏ‰_i
		= \int_0^âˆž \etc{\int_{-âˆž}^{+âˆž}}{}{} \sum_{j=1}^k \pdv{f_j}{x^j} \etc{dx^\i}{}k
	\intertext{
		All terms $\pdv{f_j}{x^j}dx^j$ in the sum for $j > 1$ integrate to boundary terms $x_j â†’ Â±âˆž$ where $f_j$ vanishes.
		This leaves the single term from the integration of $dx^1$,
	}
		&= -\etc{\int_{-âˆž}^{+âˆž}}{}{} \eval{f_1}_{x^1=0}^âˆž \etc[2]{dx^\i}k
	.\end{align}

	\end{itemize}

	Thus, we have equality for all $Ï‰_i$, so
	\begin{align}
		\int_R \dd Ï‰ = \sum_{i=1}^N \int_R \dd Ï‰_i = \sum_{i=1}^N \int_{âˆ‚R} Ï‰_i = \int_{âˆ‚R} Ï‰
	\end{align}
	by linearity.
\end{proof}

\subsection{Fundamental Theorem of Geometric Calculus}