\chapter{Preliminary Theory}


Many of the tools we will develop for the study of spacetime share the property of being associative algebras.
As well as the geometric algebra of spacetime, we will encounter tensors, exterior forms, quaternions, and other structures in this category.
Instead of defining each algebra axiomatically as needed, it is easier to develop the general theory and then define each algebra succinctly as a particular quotient of the free algebra.
This enables the use of the same tools and the same terminology for the analysis of different algebras.

Therefore, this section is an overview of the abstract theory of associative algebras, which more generally belongs to \emph{ring theory}.\sidenote{
	A \textdef{ring} is a field without the requirement that multiplicative inverses exist or that multiplication commutes; a field is a commutative ring in which non-zero elements are invertible.
}
Algebras, quotients, gradings, homogeneous and inhomogeneous multivectors are defined.
Throughout, $\FF$ denotes the underlying field of some vector space.
(Eventually, $\FF$ will always be taken to be $\RR$, but we may begin in generality.)
Most definitions in this chapter can be readily generalised by replacing the field $\FF$ with a ring.

\section{Associative Algebras}

\begin{definition}
	\label{def:associative-algebra}
	An \textdef{associative algebra} $A$ is a vector space equipped with a product $⊛ : A × A \to A$ which is associative and bilinear.
\end{definition}
Associativity means $(𝒖 ⊛ 𝒗) ⊛ 𝒘 = 𝒖 ⊛ (𝒗 ⊛ 𝒘)$, while bilinearity means the product is:
\begin{itemize}
	\item compatible with scalars: $(λ𝒖) ⊛ 𝒗 = 𝒖 ⊛ (λ𝒗) = λ(𝒖 ⊛ 𝒗)$ for $λ \in \FF$; and
	\item distributive over addition: $(𝒖 + 𝒗) ⊛ 𝒘 = 𝒖 ⊛ 𝒘 + 𝒗 ⊛ 𝒘$, and similarly for $𝒖 ⊛ (𝒗 + 𝒘)$.
\end{itemize}
This definition can be generalised by relaxing associativity or by letting $\FF$ be a ring.
However, we will use ``algebra'' exclusively to mean an associative algebra over a field (usually $\RR$).

Any ring forms an associative algebra when considered as a one-dimensional vector space.
The complex numbers can be viewed as a real $2$-dimensional algebra by defining $⊛$ to be complex multiplication;
\begin{math}
	(x_1, y_1)⊛(x_2, y_2) ≔ (x_1x_2 - y_1y_2, x_1y_2 + y_1x_2)
.\end{math}



\subsubsection{The free tensor algebra}

The most general (associative) algebra containing a given vector space $V$ is the \textdef{tensor algebra $\TA{V}$}.
The tensor product $⊗$ satisfies exactly the relations of \cref{def:associative-algebra} with no others.
Thus, the tensor algebra associative, bilinear and \emph{free} in the sense that no further information is required in its definition.

As a vector space, the tensor algebra is equal to the infinite direct sum
\begin{align}
	\label{eqn:tensor-algebra-graded-decomposition}
	\TA{V} ≅ \bigoplus_{k=0}^∞ V^{⊗k} ≡ \FF ⊕ V ⊕ (V ⊗ V) ⊕ (V ⊗ V ⊗ V) ⊕ \cdots
\end{align}
where each $\TA[k]{V}$ is the subspace of \textdef{tensors of grade $k$}.

\subsection{Quotient algebras}

Owing to the maximal generality of the free tensor algebra, any other associative algebras may be constructed as a \emph{quotient} of $\TA{V}$.
In order for a quotient $\quot{\TA{V}}{\sim}$ by an equivalence relation $\sim$ to itself form an algebra, the relation must preserve the associative algebra structure:
\begin{definition}
	\label{def:congruence}
	A \textdef{congruence} on an algebra $A$ is an equivalence relation $\sim$ which is compatible with the algebraic relations, so that if $a \sim a'$ and $b \sim b'$ then $a + b \sim a' + b'$ and $a⊛b \sim a'⊛b'$.
\end{definition}
The quotient of an algebra by a congruence naturally has the structure of an algebra, and so is called a \textdef{quotient algebra}.
\begin{lemma}
	\label{thm:quotient-algebra-by-congruence}
	The \textdef{quotient} $\quot A {\sim}$ of an algebra $A$ by a congruence $\sim$, consisting of equivalence classes $[a] \in \quot A {\sim}$ as elements, forms an algebra with the naturally inherited operations $[a] + [b] ≔ [a + b]$ and $[a]⊛[b] ≔ [a⊛b]$.
\end{lemma}
\begin{proof}
	The fact that the operations $+$ and $⊛$ of the quotient are well-defined follows from the structure-preserving properties of the congruence.
	Addition is well-defined if $[a] + [b]$ does not depend on the choice of representatives: if $a' ∈ [a]$ then $[a'] + [b]$ should be $[a] + [b]$.
	By congruence, we have from $a \sim a'$ so that $[a + b] = [a' + b]$ and indeed $[a] + [b] = [a'] + [b]$.
	Likewise for $⊛$.
\end{proof}

Instead of presenting an equivalence relation, it is often easier to define a congruence by specifying the set of elements which are equivalent to zero, from which all other equivalences follow from the algebra axioms.
Such a set of all `zeroed' elements is called an ideal.
\begin{definition}
	\label{def:ideal}
	A \textdef{(two-sided) ideal} of an algebra $A$ is a subset $I \subseteq A$ which is closed under addition and invariant under multiplication, so that
	\begin{itemize}
		\item if $a, b ∈ I$ then $a + b ∈ I$; and
		\item if $r ∈ A$ and $a ∈ I$ then $r⊛a ∈ I ∋ a⊛r$.
	\end{itemize}
\end{definition}

We will use the notation $\gen{A}$ to mean the ideal generated by setting $a \sim 0$ for all $a$ in $A$.
For example, $\gen{a} = \spanof{r ⊛ a ⊛ r' | r, r' ∈ A}$ is the ideal consisting of sums and products involving the specified element $a$, and $\gen{𝒖 ⊗ 𝒖 | 𝒖 ∈ V}$, or simply $\gen{𝒖⊗𝒖}$, is the ideal in $\TA{V}$ consisting of sums of terms of the form $a ⊗ 𝒖 ⊗ 𝒖 ⊗ b$ for vectors $𝒖$ and arbitrary $a, b ∈ \TA{V}$.

\begin{lemma}
	\label{lem:congruence-ideal-equiv}
	An ideal uniquely defines a congruence, and vice versa, by the identification of $I$ as the set of elements equivalent to zero;
	\begin{math}
		a \sim 0 \iff a ∈ I
	.\end{math}
\end{lemma}
\begin{proof}
	The set $I ≔ \set{a | a \sim 0}$ is indeed an ideal because it is closed under addition (for $a, b ∈ I$ we have $\implies a + b \sim 0 + 0 = 0$ so $a + b ∈ I$) and invariant under multiplication (for any $a ∈ I$ and $r ∈ A$, we have $r⊛a \sim r⊛0 = 0 = 0⊛r \sim a⊛r$).
	Conversely, let $a \sim a'$ and $b \sim b'$.
	Since $\sim$ respects addition:
	\begin{align}
		\begin{aligned}
			a - a' &∈ I
		\\	b - b' &∈ I
		\end{aligned}
		\;\Bigg\}
		\implies
		(a + b) - (a' + b') ∈ I
		\iff
		a + b \sim a' + b'
	,\end{align}
	and multiplication:
	\begin{align}
		\begin{aligned}
			(a - a')⊛b &∈ I
		\\	a'⊛(b - b') &∈ I
		\end{aligned}
		\;\Bigg\}
		\implies
		a⊛b - a'⊛b' ∈ I
		\iff
		a⊛b \sim a'⊛b'
	,\end{align}
	the equivalence defined by $a \sim b ⟺ a - b ∈ I$ is a congruence.
\end{proof}

The equivalence of ideals and congruences is a general feature of abstract algebra.\sidenote{
	For example, in group theory, ideals are \emph{normal subgroups} and a congruence is an equivalence relation satisfying $gag^{-1} \sim \op{id}$ whenever $a \sim \op{id}$.
	A group modulo a normal subgroup forms a quotient group.
}
Furthermore, both can be given in terms of a homomorphism between algebras,\sidenote{
	A \emph{homomorphism} is a structure-preserving map; in the case of algebras, a linear map $Ψ : A → A'$ which satisfies $Ψ(a⊛b) = Ψ(a)\mathrel{⊛'}Ψ(b)$.
} and this is often the most convenient way to define a quotient.
\begin{theorem}[first isomorphism theorem]
	\label{thm:first-iso}
	If $Ψ : A → B$ is a homomorphism, between algebras, then
	\begin{enumerate}
		\item the relation $a \sim b$ defined by $Ψ(a) = Ψ(b)$ is a congruence;
			\label{item:first-iso:cong}
		\item the kernel $I ≔ \ker Ψ$ is an ideal; and
			\label{item:first-iso:ker}
		\item the quotients $\quot{A}{\sim} ≡ \quot{A}{I} ≅ Ψ(A)$ are all isomorphic.
			\label{item:first-iso:iso}
	\end{enumerate}
\end{theorem}
\begin{proof}
	We assume $A$ and $B$ associative algebras.
	(For a proof in universal algebra, see \cite[§\,15]{gallian2021abstract-algebra}.)

	To verify \cref{item:first-iso:cong}, suppose that $Ψ(a) = Ψ(a')$ and $Ψ(b) = Ψ(b')$ and note that $Ψ(a + a') = Ψ(b + b')$ by linearity and $Ψ(a⊛b) = Ψ(a'⊛b')$ from $Ψ(a⊛b) = Ψ(a)⊛Ψ(b)$, so the congruence properties of \cref{def:congruence} are satisfied.

	For \cref{item:first-iso:ker}, note that $\ker Ψ$ is a vector subspace, and that $a ∈ \ker Ψ$ implies $a⊛r ∈ \ker Ψ$ for any $r ∈ A$ since $Ψ(a⊛r) = Ψ(a)⊛Ψ(r) = 0$.
	Thus, $\ker Ψ$ is an ideal by \cref{def:ideal}.

	The first equivalence in \cref{item:first-iso:iso} follows from \cref{lem:congruence-ideal-equiv}.
	For an isomorphism $Φ : \quot A {\ker Ψ} → Ω(A)$, pick $Φ([a]) = Ψ(a)$.
	This is well-defined because the choice of representative of the equivalence class $[a]$ does not matter; $a \sim a'$ if and only if $Ψ(a) = Ψ(a')$ by definition of $\sim$, which simultaneously shows that $Φ$ is injective.
	Surjectivity follows since any element of $Ψ(A)$ is of the form $Ψ(a)$ which is the image of $[a]$.
\end{proof}


With the free tensor algebra and \cref{thm:first-iso} in hand, we are able to describe any associative algebra as a quotient of the form $\quot{\TA{V}}{I}$.

\begin{definition}
	The \textdef{dimension} $\dim A$ of a quotient algebra $A = \quot {\TA{V}} I$ is its dimension as a vector space.
	The \textdef{base dimension} of $A$ is the dimension of the underlying vector space $V$.
\end{definition}
Algebras may be infinite-dimensional, as is the case for the tensor algebra itself (which is a quotient by the trivial ideal).



\subsection{Graded algebras}

Associative algebras may possess another layer of useful structure: a grading.
The grading of the tensor algebra has already been exhibited in \cref{eqn:tensor-algebra-graded-decomposition}.
A grading is a generalisation of the degree or rank of tensors or forms, and of the notion of parity for objects functions or polynomials.

\begin{definition}
	\label{def:grading}
	An algebra $A$ is \textdef{$R$-graded} for $(R, +)$ a monoid\,\sidenote{A \textdef{monoid} is a group without the requirement of inverses; i.e., a set with an associative binary operation for which there is an identity element.} if there exists a decomposition
	\begin{align}
		A = \bigoplus_{k ∈ R} A_{k}
	\end{align}
	such that $A_{i} ⊛ A_{j} ⊆ A_{i + j}$, i.e., $a ∈ A_{i}, b ∈ A_{j} ⟹ a ⊛ b ∈ A_{i + j}$.
\end{definition}
The monoid is usually taken to be $\NN$ or $\ZZ$ with addition, possibly modulo some integer.
The tensor algebra $\TA{V}$ is $\NN$-graded, since if $a ∈ \TA[p]{V}$ and $b ∈ \TA[q]{V}$ then $a ⊗ b ∈ \TA[p + q]{V}$.
Indeed, $\TA{V}$ is also $\ZZ$-graded if for $k < 0$ we understand $\TA[k]{V} ≔ \qty{\mathbf{0}}$ to be the trivial vector space.
The tensor algebra is also $\ZZ_p$-graded, where $\ZZ_p ≡ \quot \ZZ {p\ZZ}$ is addition modulo any $p > 0$, since the decomposition
\begin{align}
	\TA{V} = \bigoplus_{k = 0}^{p - 1} Z_k
	\qqtext{where}
	Z_k = \bigoplus_{n = 0}^∞ \TA[k + np]{V}
		= \TA[k]{V} ⊕ \TA[(k + p)]{V} ⊕ \cdots
\end{align}
satisfies $Z_i ⊗ Z_j \subseteq Z_k$ when $k ≡ i + j \mod p$.
In particular, $\TA{V}$ is $\ZZ_2$-graded,\sidenote{
	Algebras which are $\ZZ_2$-graded are sometimes called \emph{superalgebras}, with the prefix `super-' originating from supersymmetry theory.
} its elements admit a notion of \emph{parity}: elements of $Z_0 = \FF ⊗ \TA[2]{V} ⊗ \cdots$ are even, while elements of $Z_1 = V ⊗ \TA[3]{V} ⊗ \cdots$ are odd, and parity is respected by $⊗$ as it is for integers.

Importantly, just as not all functions $f : \RR → \RR$ are even or odd, not all elements of a $\ZZ_2$-graded algebra are even or odd; and more generally not all elements of a graded algebra belong to a single graded subspace.
\begin{definition}
	If $A = \bigoplus_{k ∈ R} A_{k}$ is an $R$-graded algerba, then an element $a ∈ A$ is \textdef{homogeneous} if it belongs to some $A_k$, in which case it is said to be a \textdef{$k$-vector}.
	If $a ∈ A_{k_1} ⊕ \cdots ⊕ A_{k_n}$ is inhomogeneous, we may call it a $\set{k_1, ..., k_n}$-multivector.
\end{definition}

All elements of a graded algebra are either inhomogeneous or a $k$-vector for some $k$; and each $k$-vector is either a \emph{$k$-blade }or a sum of $k$-blades.

\begin{definition}
	A \textdef{$k$-blade} is a $k$-vector $a ∈ A_k$ of the form
	\begin{math}
		a = \etc{𝒖_\i} ⊛ k
	\end{math}
	where each $𝒖_i ∈ A_1$ is a $1$-vector.
\end{definition}

Note that not all $k$-vectors are blades.
The simplest counterexample requires at least four dimensions: the bivector $\ve_1 ⊗ \ve_2 + \ve_3 ⊗ \ve_4 ∈ \TA[2]{(\RR^4)}$, where $\set{\ve_i}$ are the standard basis of $\RR^4$, cannot be factored into a blade of the form $𝒖 ⊗ 𝒗$ for any $𝒖, 𝒗 ∈ V$.

\todo{Does this even make sense for a general graded algebra??}

\subsubsection{Graded quotient algebras}

A grading structure may or may not be inherited by a quotient --- in particular, not all quotients of $\TA{V}$ inherit its $\ZZ$-grading.
When reasoning about quotients of graded algebras, the following fact is useful.
\begin{lemma}
	\label{lem:quotients-commute-with-direct-sums}
	Quotients commute with direct sums, so if
	\begin{align}
		A = \bigoplus_{k ∈ R} A_k
		\qqtext{and}
		I = \bigoplus_{k ∈ R} I_k
		\qqtext{then}
		\quot A I = \bigoplus_{k ∈ R} (\quot{A_k}{I_k})
	\end{align}
	where $R$ is some index set.
\end{lemma}
\begin{proof}
	It is sufficient to prove the case for direct sums of length two.
	We then seek an isomorphism
	\begin{math}
		Φ : \quot{(A ⊕ B)}{(I ⊕ J)} → (\quot{A}{I}) ⊕ (\quot{B}{J})
	.\end{math}
	Elements of the domain are equivalence classes of pairs $[(a, b)]$ with respect to the ideal $I ⊕ J$.
	The direct sum ideal $I ⊕ J$ corresponds to the congruence defined by $(a, b) \sim (a', b') \iff a \sim a'$ and $b \sim b'$.
	Therefore, the assignment $Φ = [(a, b)] \mapsto ([a], [b])$ is well-defined.
	Injectivity and surjectivity follow immediately.
\end{proof}
This motivates the following strengthening to the notion of an ideal:
\begin{definition}
	An ideal $I$ of an $R$-graded algebra $A = \bigoplus_{k ∈ R} A_k$ is \textdef{homogeneous} if $I = \bigoplus_{k ∈ R}I_k$ where $I_k = I \cap A_k$.
\end{definition}
Not all ideals are homogeneous.\sidenote{
	For example, the ideal $I = \gen{\ve_1 + \ve_2 ⊗ \ve_3}$ is distinct from $\bigoplus_{k = 0}^∞ (I \cap \TA[k]{V}) = \gen{\ve_1, \ve_2 ⊗ \ve_3}$ because the former does not contain $\spanof{\ve_1}$, while the latter does.
}
The additional requirement that an ideal be homogeneous ensures that the associated equivalence relation, as well as respecting the basic algebraic relations of \cref{def:congruence}, also preserves the grading structure.
And so, we have a graded analogue to \cref{thm:quotient-algebra-by-congruence}:
\begin{theorem}
	\label{thm:quotient-algebra-by-homogeneous-congruence}
	If $A$ is an $R$-graded algebra and $I$ a homogeneous ideal, then the quotient $\quot A I$ is also $R$-graded.
\end{theorem}
\begin{proof}
	By \cref{lem:quotients-commute-with-direct-sums} and the homogeneity of $I$, we have
	\begin{math}
		\quot A I = \bigoplus_{k ∈ R} (\quot{A_k}{I_k})
	.\end{math}
	Elements of $\quot{A_k}{I_k}$ are equivalence classes $[a_k]$ where the representative is of grade $k$.
	Thus, $(\quot{A_p}{I_p}) ⊛ (\quot{A_q}{I_q}) \subseteq \quot{A_{p + q}}{I_{p + q}}$ since $[a_p] ⊛ [a_q] = [a_p ⊛ a_q] = [b]$ for some $b ∈ A_{p + q}$.
	Hence, $\quot A I$ is $R$-graded.
\end{proof}



\section{The Wedge Product: Multivectors}

One of the simplest algebras to construct as a quotient of the tensor algebra, yet still one of the most useful, is the \emph{exterior algebra}, first introduced by Hermann Grassmann in 1844.
\begin{definition}
	\label{def:exterior-algebra}
	The \textdef{exterior algebra} over a vector space $V$ is
	\begin{align}
		\EA{V} ≔ \quot{\TA{V}}{ \gen{𝒖⊗𝒖}}
	.\end{align}
	The product in $\EA{V}$ is denoted $∧$ and called the \textdef{wedge product}.
\end{definition}
The ideal $\gen{𝒖 ⊗ 𝒖} ≡ \gen{𝒖 ⊗ 𝒖 | 𝒖 ∈ V}$ corresponds to the congruence $𝒖 ⊗ 𝒖 \sim 0$ for any vectors $𝒖 ∈ V$.
The wedge product is also called the \emph{exterior}, \emph{alternating} or \emph{antisymmetric} product.
The property suggested by its names may easily be seen by expanding the square of a sum;
\begin{align}
	(𝒖 + 𝒗)∧(𝒖 + 𝒗) = 𝒖∧𝒖 + 𝒖∧𝒗 + 𝒗∧𝒖 + 𝒗∧𝒗
.\end{align}
Since all terms of the form $𝒘∧𝒘 = 0$ are definitionally zero, we have
\begin{align}
	𝒖∧𝒗 = -𝒗∧𝒖
\end{align}
for all vectors $𝒖, 𝒗 ∈ V$.
By associativity, it follows that $𝒗_1 ∧ 𝒗_2 ∧ \cdots ∧ 𝒗_k$ vanishes exactly when the $𝒗_i$ are linearly dependent.\sidenote{
	\begin{proof}
		Blades of the form $a = \etc{𝒖_\i}∧k$ vanish when two or more vectors are repeated.
		If $\set{𝒖_i}$ is linearly dependent, then any one $𝒖_i$ can be written in terms of the others, and thus $a$ can be expanded into a sum of such vanishing terms.
	\end{proof}
}

The ideal $\gen{𝒖 ⊗𝒖}$ is homogeneous with respect to the $\ZZ$-grading of the parent tensor algebra.
Therefore, $\EA{V}$ is itself $\ZZ$-graded.
In particular, it is the direct sum of fixed-grade subspaces
\begin{align}
	\EA{V} = \bigoplus_{k=0}^{\dim V} \EA[k]{V}
	\qqtext{where}
	\EA[k]{V} = \spanof{𝒗_1 ∧ 𝒗_2 ∧ \cdots ∧ 𝒗_k | 𝒗_i ∈ V}
,\end{align}
and the wedge product respects grade, $(\EA[p]{V}) ∧ (\EA[q]{V}) \subseteq \EA[p + q]{V}$.
By counting the number of possible linearly independent sets of $k$ vectors in $\dim V$ dimensions, it follows that
\begin{align}
	\dim\EA[k]{V} = \binom{\dim V}{k}
,	\qqtext{and hence}
	\dim\EA{V} = 2^{\dim V}
.\end{align}
Thus, the exterior algebra with base dimension $n$ is $2^n$-dimensional.

\subsection{As antisymmetric tensors}

\label{sec:exterior-algebra-as-antisymmetric}

The exterior algebra may equivalently be viewed as the space of antisymmetric tensors equipped with an antisymmetrising product.
% Consider the (anti)\-sym\-metri\-sation map
Consider the map
\begin{align}
	\label{eqn:(anti)symmetriser}
	\op{Sym}^±(\etc{𝒖_\i}⊗k) = \frac1{k!} \sum_{σ ∈ S_k} (±1)^σ \etc{𝒖_{σ(\i)}}⊗k
\end{align}
where $(-1)^σ$ denotes the sign of the permutation $σ$ in the symmetric group of $k$ elements, $S_k$.
By enforcing linearly, $\op{Sym}^± : \TA{V} → \TA{V}$ is defined on all tensors.
A tensor $a$ is called \textdef{symmetric} if $\op{Sym}^+(a) = a$ and \textdef{antisymmetric} if $\op{Sym}^-(a) = a$.

Denote the image $\op{Sym}^-(\TA{V})$ by $S$.
The linear map $\op{Sym}^- : \TA{V} → S$ is not an algebra homomorphism with respect to the tensor product on $S$, since, e.g.,
\begin{math}
	\op{Sym}^-(𝒖⊗𝒗) ≠ \op{Sym}^-(𝒖)⊗\op{Sym}^-(𝒗) = 𝒖 ⊗ 𝒗
.\end{math}
However, it is if we instead equip $S$ with the antisymmetrising product $∧ : S × S → S$ defined by
\begin{align}
	\label{eqn:wedge-as-antisymm}
	a ∧ b ≔ \op{Sym}^-(a ⊗ b)
.\end{align}
This makes $\op{Sym}^- : \TA{V} → S$ an algebra homomorphism, and by \cref{thm:first-iso}, we have
\begin{align}
	\label{eqn:iso-of-antisym}
	% \quot{\TA{V}}{\ker \op{Sym}^-} \cong \op{Sym}^-(\TA{V})
	S \cong \quot{\TA{V}}{\ker \op{Sym}^-}
.\end{align}
Furthermore, note that the kernel of $\op{Sym}^-$ consists of tensor products of linearly dependent vectors, and sums thereof,\sidenote{
	\begin{proof}
		If $a = \etc{𝒖_\i}⊗k$ where two vectors $𝒖_i = 𝒖_j$ are equal, then $\op{Sym}^-(a) = 0$ since each term in the sum in \cref{eqn:(anti)symmetriser} is paired with an equal and opposite term with $i ↔︎ j$ swapped.
		If $\set{𝒖_i}$ is linearly dependent, any one vector is a sum of the others, so $a$ is a sum of blades with at least two vectors repeated.
	\end{proof}
}
\begin{align}
	\ker \op{Sym}^- = \spanof{\etc{𝒖_\i}⊗k | k ∈ \NN, \text{$\set{𝒖_i}$ linearly dependent}}
,\end{align}
which is exactly the ideal $\gen{𝒖⊗𝒖}$.
Therefore, the left-hand side of \cref{eqn:iso-of-antisym} is the exterior algebra of \cref{def:exterior-algebra}, and we have an algebra isomorphism
\begin{math}
	\EA{V} \cong \op{Sym}^-(\TA{V})
,\end{math}
where the right-hand side is equipped with the product \eqref{eqn:wedge-as-antisymm}.
This gives an alternative construction of the exterior algebra.

\subsubsection{Note on conventions}

The factor of $\frac1{k!}$ present in \cref{eqn:(anti)symmetriser} is not necessary for the above demonstration that $\EA{V} \cong \op{Sym}^-(\TA{V})$.
Indeed, some authors omit the normalisation factor, which has the effect of changing \cref{eqn:wedge-as-antisymm} to
\begin{align}
	a ∧ b = \frac{(p + q)!}{p!q!}\op{Sym}^-(a ⊗ b)
\end{align}
for $a ∈ \op{Sym}^-(\TA[p]{V})$ and $b ∈ \op{Sym}^-(\TA[q]{V})$, in terms of our convention \eqref{eqn:(anti)symmetriser}.
The different definitions of $∧$ as an antisymmetrising product lead to different identifications of $\EA{V}$ with $S$, as clarified in \cref{tbl:wedge-conventions}.
\begin{table}[h]
	\centering
	\setlength{\tabcolsep}{20pt}
	\renewcommand{\arraystretch}{1.5}
	\begin{tabular}{cc}
		\emph{Kobayashi--Nomizu} \cite{kobayashi1963dg}
	&	\emph{Spivak} \cite{spivak1975dg}
	\\	$a ∧ b ≔ \op{Sym}^-(a⊗b)$
	&	$a ∧ b ≔ \frac{(p + q)!}{p!q!}\op{Sym}^-(a⊗b) $
	\\	$𝒖 ∧ 𝒗 = \frac12(𝒖⊗𝒗 - 𝒗⊗𝒖)$
	&	$𝒖 ∧ 𝒗 = 𝒖⊗𝒗 - 𝒗⊗𝒖$
	\end{tabular}
	\caption{
		Different embeddings of $\EA{V}$ into $\TA{V}$.
		We employ the Kobayashi--Nomizu convention as this is coincides with the wedge product of geometric algebra.
		The Spivak convention is dominant for differential forms in physics.
	}
	\label{tbl:wedge-conventions}
\end{table}


\subsection{Exterior forms}

The exterior algebra is most frequently encountered by physicists in the context of \emph{exterior (differential) forms}, which are alternating\sidenote{
	An \textdef{alternating} linear map is one which changes sign upon any transposition of any pair of arguments.
	E.g., if $f$ is alternating, then $f(𝒖, 𝒗, 𝒘) = -f(𝒗, 𝒖, 𝒘)$.
} multilinear maps.

We may wish to use the exterior algebra $\EA{V^*}$ over the dual space of linear maps $V → \RR$ as a model for exterior forms.
Using the dual basis $\set{\ve^i} ⊂ V^*$, any element $f ∈ \EA[k]{V^*}$ has the form $f = f_{\etc{i_\i}{}k} \etc{\ve^{i_\i}}∧k$, and each component acts on $\etc{𝒖_\i}⊗k ∈ \TA[k]{V}$ as
\begin{align}
	\label{eqn:poor-mans-exterior-form}
	(\etc{\ve^{i_\i}}∧k)(\etc{𝒖_\i}⊗k) = \frac1{k!} \sum_{σ ∈ S_k} (-1)^σ\etc{\ve^{i_{σ(\i)}}(𝒖_\i)}{}k
.\end{align}
However, this differs from the standard definition of exterior forms in two important ways:
\begin{enumerate}
	\item In \cref{eqn:poor-mans-exterior-form}, the dual vectors $\ve^i ∈ V^*$ are permuted while the order of the arguments $𝒖_i$ are preserved; but for standard exterior forms, the opposite is true.
	This prevents the proper extension of $\EA{V^*}$ to non-Abelian vector-valued forms, where the values $\ve^i(𝒖_j)$ may not commute.
	\item Trivially, we insist on the the Kobayashi---Nomizu convention of normalisation factor for $\EA{V^*}$; but the Spivak convention for exterior forms is much more standard in physics.
\end{enumerate}
Thus, we define exterior forms separately in order to match convention.

\begin{definition}
	For a vector space $V$, a \textdef{$k$-form} $φ ∈ \forms[k](V)$ is an alternating multilinear map $φ : \TA[k]{V} → \RR$.
	For another vector space $A$, an \textdef{$A$-valued $k$-form} $φ ∈ \forms[k](V, A)$ is such a map $φ : \TA[k]{V} → A$ into $A$.
\end{definition}
The evaluation of a form is denoted $φ(\etc{𝒖_\i}⊗k)$ or $φ(\etc{𝒖_\i},k)$, and the wedge product of a $p$-form $φ$ and $q$-form $ϕ$ is defined (in the Spivak convention)
\begin{align}
	\label{eqn:wedge-of-forms}
	φ ∧ ϕ = \frac{(p + q)!}{p!q!} (φ ⊗ ϕ) \circ \op{Sym}^-
.\end{align}
Explicitly, \cref{eqn:wedge-of-forms} acts to antisymmetrise arguments.
To see this, choose a basis $\set{\dx^μ}$ of $\forms(V)$, and compare to \cref{eqn:poor-mans-exterior-form},
\begin{align}
 	(\etc{\dx^{μ_\i}}∧k)(\etc{𝒖_\i}⊗k) = \sum_{σ ∈ S_k} (-1)^σ \etc{\dx^{μ_\i}(𝒖_{σ(\i)})}{}k
.\end{align}

If $φ, ϕ ∈ \forms(V, A)$ are $A$-valued forms, where $A$ is equipped with a bilinear product $⊛ : A × A → A$, then scalar multiplication may be replaced this product, so that
\begin{align}
	(φ ∧ ϕ)(\etc{𝒖_\i} ⊗ k) = \sum_{σ ∈ S_k} (-1)^σ φ(\etc{𝒖_\i} ⊗ p) ⊛ ϕ(\etc{𝒖_\i} ⊗ q)
.\end{align}
The product $⊛$ need not be commutative or associative; in particular, we may have Lie algebra--valued forms.
For example, if $φ, ϕ ∈ \forms[1](V, \liealg g)$ are Lie algebra--valued, then
\begin{align}
	(φ ∧ ϕ)(𝒖, 𝒗) = [φ(𝒖), ϕ(𝒗)] - [φ(𝒗), ϕ(𝒖)]
,\end{align}
where $[\phantom{𝒖}, \phantom{𝒖}] : \liealg g × \liealg g → \liealg g$ is the Lie bracket.
Note that this implies that $φ ∧ φ$ does not necessarily vanish for non-Abelian forms --- in the case above we have $(φ ∧ φ)(𝒖, 𝒗) = 2[φ(𝒖), φ(𝒗)]$.
% \begin{align}
% 	φ ∧ ϕ = \op{Alt}(φ ⊗ ϕ)
% \end{align}
% where the alternating map
% \begin{align}
% 	\op{Alt}(f)(\etc{𝒖_\i}⊗k) = k! f(\op{Sym}^-(\etc{𝒖_\i}⊗k))
% \end{align}
% antisymmetrises arguments to the multilinear function $f$.
 


\section{The Metric: Length and Angle}

The tensor and exterior algebras considered so far are build from a vector space $V$ alone.
Notions of length and angle are central to geometry, but are not intrinsic to a vector space --- additional structure must be provided.
\begin{definition}
	A \textdef{metric}\,\sidenote{a.k.a. an \emph{inner product}, or \emph{symmetric bilinear form}} is a function $η : V × V \to \FF$, often written
	$ η(𝒖, 𝒗) ≡ \ip{𝒖, 𝒗} $
	which satisfies
	\begin{itemize}
		\item symmetry, $\ip{𝒖, 𝒗} = \ip{𝒗, 𝒖}$; and
		\item linearity, $\ip{α𝒖 + β𝒗, 𝒘} = α\ip{𝒖, 𝒘} + β\ip{𝒗, 𝒘}$ for $α, β \in \FF$.
	\end{itemize}
\end{definition}

Linearity in either argument implies linearity in the other by symmetry, so $η$ is bilinear.

A vector space $V$ together with a metric $η$ is called an \textdef{inner product space} $(V, η)$.
Alternatively, instead of a metric, an inner product space may be constructed with a quadratic form:
\begin{definition}
	A \textdef{quadratic form} is a function $q : V \to \FF$ satisfying
	\begin{itemize}
		\item $q(λ𝒗) = λ^2q(𝒗)$ for all $λ \in \FF$; and
		\item the requirement that the \textdef{polarization of $q$},
		\begin{align}
			(𝒖, 𝒗) \mapsto q(𝒖 + 𝒗) - q(𝒖) - q(𝒗)
		,\end{align}
		is bilinear.
	\end{itemize}
\end{definition}
To any quadratic form $q$ there is a unique associated bilinear form, which is \emph{compatible} in the sense that $q(𝒖) = \ip{𝒖,𝒖}$.
It is recovered\sidenote{
	Except, of course, if the characteristic of $\FF$ is two.
	We only consider fields of characteristic zero.
} by the \emph{polarization identity}
\begin{align}
	\ip{𝒖, 𝒗} = \frac12\qty\big(q(𝒖 + 𝒗) - q(𝒖) - q(𝒗))
.\end{align}
The prescription of either $η$ or $q$ is therefore equivalent --- but the notion of a metric is more common in physics, whereas the mathematical viewpoint often starts with a quadratic form.


