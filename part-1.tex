\part{Special Relativity and Geometric Algebra}
\label{part:1}

\chapter{Introduction}

The Special Theory of Relativity is a model of \emph{spacetime} --- the geometry in which physical events take place.
Spacetime comprises the Euclidean dimensions of space and time, but only in a way relative to each observer moving through it: there exists no single `universal' ruler or clock.
Instead, two observers in relative motion define different decompositions of spacetime, and their respective clocks and rulers are found to disagree according to the Lorentz transformation laws.
The insight of special relativity is that one should focus not on the observer-dependent notions of space and time, but on the Lorentzian geometry of spacetime itself.

Seven years after Albert Einstein introduced this theory,\sidenote{
	Einstein’s paper \cite{einstein1905electrodynamics} was published in 1905, the so-called \emph{Annus Mirabilis} or ``miracle year'' during which he also published on the photoelectric effect, Brownian motion and the mass-energy equivalence.
	Each of the four papers was a monumental contribution to modern physics.
} he succeeded in formulating a relativistic picture which included gravity.
In this General Theory of Relativity, gravitation is identified with the curvature of spacetime over astronomical distances.
Both theories coincide locally when confined to sufficiently small extents of spacetime, over which the effects of curvature are negligible.
In \cref{part:1}, we will focus on special relativity, leaving gravity and curvature to \cref{part:2}.

In the wake of the Erlangen programme,\sidenote{
	Introduced by Felix Klein in 1872 \cite{klein1893erlangen}, the Erlangen program is the characterisation of geometries (Euclidean, hyperbolic, projective, etc.) by their symmetry groups and the properties invariant under those groups.
	E.g., Euclidean geometry studies the invariants of rigid transformations.
} the study of local spacetime geometry amounts to the study of its intrinsic symmetries.
These symmetries form the Poincaré group, and consist of spacetime translations and Lorentz transformations, the latter being the extension of the group of rotations of Euclidean space to the relativistic rotations of spacetime.
The standard matrix representation of the Lorentz group, $\SO^+(1, 3)$, is the connected component of the orthogonal group
\begin{align}
	\op{O}(1,3) = \set{\lin Λ ∈ \GL(\RR^4) | \lin Λ\trans\lin η\lin Λ = \lin η}
\end{align}
with respect to the bilinear form $η = ±\op{diag}(-1,+1,+1,+1)$.
The rudimentary tools of matrix algebra are sufficient for an analys the Lorentz group, and are familiar to any physicist.

However, the last century has seen many other mathematical tools be applied to the study of generalised rotation groups such as $\SO^+(1,3)$ or the rotation group $\SO(3)$ of $\RR^3$.
Among these tools is the \emph{geometric algebra}, invented\sidenote{
	Clifford algebra was independently discovered by Rudolf Lipschitz two years later \cite{lipschitz1880clifford-alg}. 
	He was the first to use them to the study the orthogonal groups.
} by William Clifford in 1878 \cite{clifford1878grassmann}.
Geometric algebra remains largely unknown in the physics community, despite arguably being far superior for the analysis of rotations than traditional matrix techniques.
It is informative to glean some of the history that led to this (perhaps unfortunate) state of affairs.

\subsubsection{The quest for an optimal formalism for rotations}

Mathematics has seen the invention of a variety of vector formalisms since the 1800s, and the question of which is best suited to physics has a long contentious history.

The vector algebra ``war'' of 1890--1945 saw William Hamilton's prized quaternion algebra $\HH$, hailed as the optimal tool for describing rotations in $\RR^3$, struggle for popularity before being eventually left to gather dust as an old-fashioned curiosity.



\chapter{Preliminary Theory}


Many of the tools we will develop for the study of spacetime share the property of being associative algebras.
As well as the geometric algebra of spacetime, we will encounter tensors, exterior forms, quaternions, and other structures in this category.
Instead of defining each algebra axiomatically as needed, it is easier to develop the general theory and then define each algebra succinctly as a particular quotient of the free algebra.
This enables the use of the same tools and the same terminology for the analysis of different algebras.

Therefore, this section is an overview of the abstract theory of associative algebras, which more generally belongs to \emph{ring theory}.\sidenote{
	A \textdef{ring} is a field without the requirement that multiplicative inverses exist or that multiplication commutes; a field is a commutative ring in which non-zero elements are invertible.
}
Algebras, quotients, gradings, homogeneous and inhomogeneous multivectors are defined.
Throughout, $\FF$ denotes the underlying field of some vector space.
(Eventually, $\FF$ will always be taken to be $\RR$, but we may begin in generality.)
Most definitions in this chapter can be readily generalised by replacing the field $\FF$ with a ring.

\section{Associative Algebras}

\begin{definition}
	\label{def:associative-algebra}
	An \textdef{associative algebra} $A$ is a vector space equipped with a product $⊛ : A × A \to A$ which is associative and bilinear.
\end{definition}
Associativity means $(𝒖 ⊛ 𝒗) ⊛ 𝒘 = 𝒖 ⊛ (𝒗 ⊛ 𝒘)$, while bilinearity means the product is:
\begin{itemize}
	\item compatible with scalars: $(λ𝒖) ⊛ 𝒗 = 𝒖 ⊛ (λ𝒗) = λ(𝒖 ⊛ 𝒗)$ for $λ \in \FF$; and
	\item distributive over addition: $(𝒖 + 𝒗) ⊛ 𝒘 = 𝒖 ⊛ 𝒘 + 𝒗 ⊛ 𝒘$, and similarly for $𝒖 ⊛ (𝒗 + 𝒘)$.
\end{itemize}
This definition can be generalised by relaxing associativity or by letting $\FF$ be a ring.
However, we will use ``algebra'' exclusively to mean an associative algebra over a field (usually $\RR$).

Any ring forms an associative algebra when considered as a one-dimensional vector space.
The complex numbers can be viewed as a real $2$-dimensional algebra by defining $⊛$ to be complex multiplication;
\begin{math}
	(x_1, y_1)⊛(x_2, y_2) ≔ (x_1x_2 - y_1y_2, x_1y_2 + y_1x_2)
.\end{math}



\subsubsection{The free tensor algebra}

The most general (associative) algebra containing a given vector space $V$ is the \textdef{tensor algebra $\TA{V}$}.
The tensor product $⊗$ satisfies exactly the relations of \cref{def:associative-algebra} with no others.
Thus, the tensor algebra associative, bilinear and \emph{free} in the sense that no further information is required in its definition.

As a vector space, the tensor algebra is equal to the infinite direct sum
\begin{align}
	\label{eqn:tensor-algebra-graded-decomposition}
	\TA{V} ≅ \bigoplus_{k=0}^∞ V^{⊗k} ≡ \FF ⊕ V ⊕ (V ⊗ V) ⊕ (V ⊗ V ⊗ V) ⊕ \cdots
\end{align}
where each $\TA[k]{V}$ is the subspace of \textdef{tensors of grade $k$}.

\subsection{Quotient algebras}

Owing to the maximal generality of the free tensor algebra, any other associative algebras may be constructed as a \emph{quotient} of $\TA{V}$.
In order for a quotient $\quot{\TA{V}}{\sim}$ by an equivalence relation $\sim$ to itself form an algebra, the relation must preserve the associative algebra structure:
\begin{definition}
	\label{def:congruence}
	A \textdef{congruence} on an algebra $A$ is an equivalence relation $\sim$ which is compatible with the algebraic relations, so that if $a \sim a'$ and $b \sim b'$ then $a + b \sim a' + b'$ and $a⊛b \sim a'⊛b'$.
\end{definition}
The quotient of an algebra by a congruence naturally has the structure of an algebra, and so is called a \textdef{quotient algebra}.
\begin{lemma}
	\label{thm:quotient-algebra-by-congruence}
	The \textdef{quotient} $\quot A {\sim}$ of an algebra $A$ by a congruence $\sim$, consisting of equivalence classes $[a] \in \quot A {\sim}$ as elements, forms an algebra with the naturally inherited operations $[a] + [b] ≔ [a + b]$ and $[a]⊛[b] ≔ [a⊛b]$.
\end{lemma}
\begin{proof}
	The fact that the operations $+$ and $⊛$ of the quotient are well-defined follows from the structure-preserving properties of the congruence.
	Addition is well-defined if $[a] + [b]$ does not depend on the choice of representatives: if $a' ∈ [a]$ then $[a'] + [b]$ should be $[a] + [b]$.
	By congruence, we have from $a \sim a'$ so that $[a + b] = [a' + b]$ and indeed $[a] + [b] = [a'] + [b]$.
	Likewise for $⊛$.
\end{proof}

Instead of presenting an equivalence relation, it is often easier to define a congruence by specifying the set of elements which are equivalent to zero, from which all other equivalences follow from the algebra axioms.
Such a set of all `zeroed' elements is called an ideal.
\begin{definition}
	\label{def:ideal}
	A \textdef{(two-sided) ideal} of an algebra $A$ is a subset $I \subseteq A$ which is closed under addition and invariant under multiplication, so that
	\begin{itemize}
		\item if $a, b ∈ I$ then $a + b ∈ I$; and
		\item if $r ∈ A$ and $a ∈ I$ then $r⊛a ∈ I ∋ a⊛r$.
	\end{itemize}
\end{definition}

We will use the notation $\gen{A}$ to mean the ideal generated by setting $a \sim 0$ for all $a$ in $A$.
For example, $\gen{a} = \spanof{r ⊛ a ⊛ r' | r, r' ∈ A}$ is the ideal consisting of sums and products involving the specified element $a$, and $\gen{𝒖 ⊗ 𝒖 | 𝒖 ∈ V}$, or simply $\gen{𝒖⊗𝒖}$, is the ideal in $\TA{V}$ consisting of sums of terms of the form $\cdots ⊗ 𝒖 ⊗ 𝒖 ⊗ \cdots$ for vectors $𝒖$.

\begin{lemma}
	\label{lem:congruence-ideal-equiv}
	An ideal uniquely defines a congruence, and vice versa, by the identification of $I$ as the set of elements equivalent to zero;
	\begin{math}
		a \sim 0 \iff a ∈ I
	.\end{math}
\end{lemma}
\begin{proof}
	The set $I ≔ \set{a | a \sim 0}$ is indeed an ideal because it is closed under addition (for $a, b ∈ I$ we have $\implies a + b \sim 0 + 0 = 0$ so $a + b ∈ I$) and invariant under multiplication (for any $a ∈ I$ and $r ∈ A$, we have $r⊛a \sim r⊛0 = 0 = 0⊛r \sim a⊛r$).
	Conversely, let $a \sim a'$ and $b \sim b'$.
	Since $\sim$ respects addition:
	\begin{align}
		\begin{aligned}
			a - a' &∈ I
		\\	b - b' &∈ I
		\end{aligned}
		\;\Bigg\}
		\implies
		(a + b) - (a' + b') ∈ I
		\iff
		a + b \sim a' + b'
	,\end{align}
	and multiplication:
	\begin{align}
		\begin{aligned}
			(a - a')⊛b &∈ I
		\\	a'⊛(b - b') &∈ I
		\end{aligned}
		\;\Bigg\}
		\implies
		a⊛b - a'⊛b' ∈ I
		\iff
		a⊛b \sim a'⊛b'
	,\end{align}
	the equivalence defined by $a \sim b ⟺ a - b ∈ I$ is a congruence.
\end{proof}

The equivalence of ideals and congruences is a general feature of abstract algebra.\sidenote{
	For example, in group theory, ideals are \emph{normal subgroups} and a congruence is an equivalence relation satisfying $gag^{-1} \sim \op{id}$ whenever $a \sim \op{id}$.
	A group modulo a normal subgroup forms a quotient group.
}
Furthermore, both can be given in terms of a homomorphism between algebras,\sidenote{
	A \emph{homomorphism} is a structure-preserving map; in the case of algebras, a linear map $Ψ : A → A'$ which satisfies $Ψ(a⊛b) = Ψ(a)\mathrel{⊛'}Ψ(b)$.
} and this is often the most convenient way to define a quotient.
\begin{theorem}[first isomorphism theorem]
	\label{thm:first-iso}
	If $Ψ : A → B$ is a homomorphism, between algebras, then
	\begin{enumerate}
		\item the relation $a \sim b$ defined by $Ψ(a) = Ψ(b)$ is a congruence;
			\label{item:first-iso:cong}
		\item the kernel $I ≔ \ker Ψ$ is an ideal; and
			\label{item:first-iso:ker}
		\item the quotients $\quot{A}{\sim} ≡ \quot{A}{I} ≅ Ψ(A)$ are all isomorphic.
			\label{item:first-iso:iso}
	\end{enumerate}
\end{theorem}
\begin{proof}
	We assume $A$ and $B$ associative algebras.
	(For a proof in universal algebra, see \cite[§\,15]{gallian2021abstract-algebra}.)

	To verify \cref{item:first-iso:cong}, suppose that $Ψ(a) = Ψ(a')$ and $Ψ(b) = Ψ(b')$ and note that $Ψ(a + a') = Ψ(b + b')$ by linearity and $Ψ(a⊛b) = Ψ(a'⊛b')$ from $Ψ(a⊛b) = Ψ(a)⊛Ψ(b)$, so the congruence properties of \cref{def:congruence} are satisfied.

	For \cref{item:first-iso:ker}, note that $\ker Ψ$ is a vector subspace, and that $a ∈ \ker Ψ$ implies $a⊛r ∈ \ker Ψ$ for any $r ∈ A$ since $Ψ(a⊛r) = Ψ(a)⊛Ψ(r) = 0$.
	Thus, $\ker Ψ$ is an ideal by \cref{def:ideal}.

	The first equivalence in \cref{item:first-iso:iso} follows from \cref{lem:congruence-ideal-equiv}.
	For an isomorphism $Φ : \quot A {\ker Ψ} → Ω(A)$, pick $Φ([a]) = Ψ(a)$.
	This is well-defined because the choice of representative of the equivalence class $[a]$ does not matter; $a \sim a'$ if and only if $Ψ(a) = Ψ(a')$ by definition of $\sim$, which simultaneously shows that $Φ$ is injective.
	Surjectivity follows since any element of $Ψ(A)$ is of the form $Ψ(a)$ which is the image of $[a]$.
\end{proof}


With the free tensor algebra and \cref{thm:first-iso} in hand, we are able to describe any associative algebra as a quotient of the form $\quot{\TA{V}}{I}$.

\begin{definition}
	The \textdef{dimension} $\dim A$ of a quotient algebra $A = \quot {\TA{V}} I$ is its dimension as a vector space.
	The \textdef{base dimension} of $A$ is the dimension of the underlying vector space $V$.
\end{definition}
Algebras may be infinite-dimensional, as is the case for the tensor algebra itself (which is a quotient by the trivial ideal).



\subsection{Graded algebras}

Associative algebras may possess another layer of useful structure: a grading.
The grading of the tensor algebra has already been exhibited in \cref{eqn:tensor-algebra-graded-decomposition}.
A grading is a generalisation of the degree or rank of tensors or forms, and of the notion of parity for objects functions or polynomials.

\begin{definition}
	\label{def:grading}
	An algebra $A$ is \textdef{$R$-graded} for $(R, +)$ a monoid\,\sidenote{A \textdef{monoid} is a group without the requirement of inverses; i.e., a set with an associative binary operation for which there is an identity element.} if there exists a decomposition
	\begin{align}
		A = \bigoplus_{k ∈ R} A_{k}
	\end{align}
	such that $A_{i} ⊛ A_{j} ⊆ A_{i + j}$, i.e., $a ∈ A_{i}, b ∈ A_{j} ⟹ a ⊛ b ∈ A_{i + j}$.
\end{definition}
The monoid is usually taken to be $\NN$ or $\ZZ$ with addition, possibly modulo some integer.
The tensor algebra $\TA{V}$ is $\NN$-graded, since if $a ∈ \TA[p]{V}$ and $b ∈ \TA[q]{V}$ then $a ⊗ b ∈ \TA[p + q]{V}$.
Indeed, $\TA{V}$ is also $\ZZ$-graded if for $k < 0$ we understand $\TA[k]{V} ≔ \qty{\mathbf{0}}$ to be the trivial vector space.
The tensor algebra is also $\ZZ_p$-graded, where $\ZZ_p ≡ \quot \ZZ {p\ZZ}$ is addition modulo any $p > 0$, since the decomposition
\begin{align}
	\TA{V} = \bigoplus_{k = 0}^{p - 1} Z_k
	\qqtext{where}
	Z_k = \bigoplus_{n = 0}^∞ \TA[k + np]{V}
		= \TA[k]{V} ⊕ \TA[(k + p)]{V} ⊕ \cdots
\end{align}
satisfies $Z_i ⊗ Z_j \subseteq Z_k$ when $k ≡ i + j \mod p$.
In particular, $\TA{V}$ is $\ZZ_2$-graded,\sidenote{
	Algebras which are $\ZZ_2$-graded are sometimes called \emph{superalgebras}, with the prefix `super-' originating from supersymmetry theory.
} its elements admit a notion of \emph{parity}: elements of $Z_0 = \FF ⊗ \TA[2]{V} ⊗ \cdots$ are even, while elements of $Z_1 = V ⊗ \TA[3]{V} ⊗ \cdots$ are odd, and parity is respected by $⊗$ as it is for integers.

Importantly, not all elements of a $\ZZ_2$-graded algebra are even or odd, and more generally not all elements of a graded algebra belong to a single graded subspace.
\begin{definition}
	If $A = \bigoplus_{k ∈ R} A_{k}$ is an $R$-graded algerba, then an element $a ∈ A$ is \textdef{homogeneous} if it belongs to some $A_k$, in which case it is said to be a \textdef{$k$-vector}.
	If $a ∈ A_{k_1} ⊕ \cdots ⊕ A_{k_n}$ is inhomogeneous, we may call it a $\set{k_1, ..., k_n}$-multivector.
\end{definition}

A grading structure may or may not be inherited by a quotient --- in particular, not all quotients of $\TA{V}$ inherit its $\ZZ$-grading.
When reasoning about quotients of graded algebras, the following fact is useful.
\begin{lemma}
	\label{lem:quotients-commute-with-direct-sums}
	Quotients commute with direct sums, so if
	\begin{align}
		A = \bigoplus_{k ∈ R} A_k
		\qqtext{and}
		I = \bigoplus_{k ∈ R} I_k
		\qqtext{then}
		\quot A I = \bigoplus_{k ∈ R} (\quot{A_k}{I_k})
	\end{align}
	where $R$ is some index set.
\end{lemma}
\begin{proof}
	It is sufficient to prove the case for direct sums of length two.
	We then seek an isomorphism
	\begin{math}
		Φ : \quot{(A ⊕ B)}{(I ⊕ J)} → (\quot{A}{I}) ⊕ (\quot{B}{J})
	.\end{math}
	Elements of the domain are equivalence classes of pairs $[(a, b)]$ with respect to the ideal $I ⊕ J$.
	The direct sum ideal $I ⊕ J$ corresponds to the congruence defined by $(a, b) \sim (a', b') \iff a \sim a'$ and $b \sim b'$.
	Therefore, the assignment $Φ = [(a, b)] \mapsto ([a], [b])$ is well-defined.
	Injectivity and surjectivity follow immediately.
\end{proof}
This motivates the following strengthening to the notion of an ideal:
\begin{definition}
	An ideal $I$ of an $R$-graded algebra $A = \bigoplus_{k ∈ R} A_k$ is \textdef{homogeneous} if $I = \bigoplus_{k ∈ R}I_k$ where $I_k = I \cap A_k$.
\end{definition}
Not all ideals are homogeneous.\sidenote{
	For example, the ideal $I = \gen{\ve_1 + \ve_2 ⊗ \ve_3}$ is distinct from $\bigoplus_{k = 0}^∞ (I \cap \TA[k]{V}) = \gen{\ve_1, \ve_2 ⊗ \ve_3}$ because the former does not contain $\spanof{\ve_1}$, while the latter does.
}
The additional requirement that an ideal be homogeneous ensures that the associated equivalence relation, as well as respecting the basic algebraic relations of \cref{def:congruence}, also preserves the grading structure.
And so, we have a graded analogue to \cref{thm:quotient-algebra-by-congruence}:
\begin{theorem}
	\label{thm:quotient-algebra-by-homogeneous-congruence}
	If $A$ is an $R$-graded algebra and $I$ a homogeneous ideal, then the quotient $\quot A I$ is also $R$-graded.
\end{theorem}
\begin{proof}
	By \cref{lem:quotients-commute-with-direct-sums} and the homogeneity of $I$, we have
	\begin{math}
		\quot A I = \bigoplus_{k ∈ R} (\quot{A_k}{I_k})
	.\end{math}
	Elements of $\quot{A_k}{I_k}$ are equivalence classes $[a_k]$ where the representative is of grade $k$.
	Thus, $(\quot{A_p}{I_p}) ⊛ (\quot{A_q}{I_q}) \subseteq \quot{A_{p + q}}{I_{p + q}}$ since $[a_p] ⊛ [a_q] = [a_p ⊛ a_q] = [b]$ for some $b ∈ A_{p + q}$.
	Hence, $\quot A I$ is $R$-graded.
\end{proof}



\section{The Wedge Product}

One of the simplest algebras to construct as a quotient $\quot {\TA{V}} I$, yet still one of the most useful, is the \emph{exterior algebra}, first introduced by Hermann Grassmann in 1844.
\begin{definition}
	\label{def:exterior-algebra}
	The \textdef{exterior algebra} over a vector space $V$ is
	\begin{align}
		\EA{V} ≔ \quot{\TA{V}}{ \gen{𝒖⊗𝒖}}
	.\end{align}
	The product in $\EA{V}$ is denoted $∧$ and called the \textdef{wedge product}.
\end{definition}
The ideal $\gen{𝒖 ⊗ 𝒖} ≡ \gen{𝒖 ⊗ 𝒖 | 𝒖 ∈ V}$ corresponds to the congruence $𝒖 ⊗ 𝒖 \sim 0$ for any vectors $𝒖 ∈ V$.
The wedge product is also called the \emph{exterior}, \emph{alternating} or \emph{antisymmetric} product.
The property suggested by its names may easily be seen by expanding the square of a sum;
\begin{align}
	(𝒖 + 𝒗)∧(𝒖 + 𝒗) = 𝒖∧𝒖 + 𝒖∧𝒗 + 𝒗∧𝒖 + 𝒗∧𝒗
.\end{align}
Since all terms of the form $𝒘∧𝒘 = 0$ are definitionally zero, we have
\begin{align}
	𝒖∧𝒗 = -𝒗∧𝒖
\end{align}
for all vectors $𝒖, 𝒗 ∈ V$.
By associativity, it follows that $𝒗_1 ∧ 𝒗_2 ∧ \cdots ∧ 𝒗_k$ vanishes exactly when the $𝒗_i$ are linearly dependent.

